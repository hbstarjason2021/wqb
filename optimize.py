import requests
import json
import pandas as pd
from requests.auth import HTTPBasicAuth
import time
import random
import logging
import re
import hashlib
import os
import threading
import signal
import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
import smtplib
from email.mime.text import MIMEText
from email.header import Header

# ==================== ç”¨æˆ·é…ç½®åŒºåŸŸ ====================
# è¿è¡Œæ¨¡å¼é…ç½®
# RUN_MODE = 1: é‡æ–°å¼€å§‹ï¼Œåˆ é™¤æ—§çš„æ—¥å¿—å’Œæ£€æŸ¥ç‚¹æ–‡ä»¶
# RUN_MODE = 2: æ–­ç‚¹ç»­çˆ¬
RUN_MODE = 1

# æ”¯æŒå¤šä¸ªAlpha IDçš„åˆ—è¡¨
TARGET_ALPHA_IDS = ['AlphaID','AlphaID']

# ä»é…ç½®æ–‡ä»¶ä¸­è¯»å–é‚®ç®±é…ç½®
try:
    with open('email_config.json') as f:
        EMAIL_CONFIG = json.load(f)

except Exception as e:
    # é»˜è®¤é‚®ç®±é…ç½®
    EMAIL_CONFIG = {
        'enabled': False,
        'smtp_server': 'smtp.qq.com',
        'smtp_port': 465,
        'sender': '',
        'password': '',
        'receiver': ''
    }
print(f"ğŸ“§ é‚®ä»¶é€šçŸ¥åŠŸèƒ½: {'å·²å¯ç”¨' if EMAIL_CONFIG.get('enabled') else 'æœªå¯ç”¨'}")

# æœ€å¤§å¹¶å‘æ•°è®¾ç½®ï¼ˆå¡æ§½æ•°é‡ï¼‰
MAX_CONCURRENT = 8

# çˆ¬å±±èµ·å§‹ä½ç½®é…ç½®
START_OPTIMIZATION_FROM = {
    'data_field': 0,
    'time_window': 0,
    'number': 0,
    'group': 0,
    'operator': 0
}

# è¿­ä»£ä¼˜åŒ–é…ç½®
MAX_ITERATIONS = 5
BATCH_SIZE = 8
PASS_BONUS = 1.0

# å€™é€‰é¡¹é…ç½®
CANDIDATE_DAYS = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 16, 22, 60, 64, 120, 128, 252, 256, 512, 720, 900, 1050, 2000]
CANDIDATE_NUMBERS = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
CANDIDATE_GROUPS = ['market', 'industry', 'subindustry', 'sector', 'density(pv13_h_fl_sector)']
CANDIDATE_NEUTRALIZATIONS = ["MARKET", "INDUSTRY", "SUBINDUSTRY", "SECTOR", "NONE", "CROWDING", "FAST", "SLOW", "RAM"]
CANDIDATE_DECAYS = [0, 1, 4, 16, 64, 128, 256, 512]

# 2.4ç‰ˆæœ¬æ”¹è‰²é€»è¾‘å¸¸é‡
MARGIN_THRESHOLD = 0.000
SC_CUTOFF = 0.7

# è¿ç®—ç¬¦æ± åˆ†ç±»
OPERATOR_GROUPS = {
    'group': [
        'group_rank', 'group_zscore', 'group_neutralize', 'group_mean', 'group_max', 'group_min',
        'group_sum', 'group_std_dev', 'group_count', 'group_scale', 'group_backfill', 'group_cartesian_product'
    ],
    'time_series': [
        'ts_rank', 'ts_zscore', 'ts_mean', 'ts_std_dev', 'ts_delta', 'ts_delay',
        'ts_backfill', 'ts_av_diff', 'ts_arg_min', 'ts_arg_max', 'days_from_last_change',
        'ts_quantile', 'ts_scale', 'ts_regression', 'ts_sum', 'ts_decay_linear',
        'ts_covariance', 'ts_count_nans', 'kth_element', 'ts_corr', 'ts_product',
        'hump', 'ts_step', 'ts_target_tvr_decay', 'last_diff_value', 'ts_target_tvr_hump',
        'ts_ir', 'ts_kurtosis', 'ts_max_diff', 'ts_returns'
    ],
    'cross_sectional': [
        'rank', 'zscore', 'scale', 'normalize', 'quantile', 'winsorize'
    ],
    'arithmetic': [
        'add', 'subtract', 'multiply', 'divide', 'pasteurize', 'sqrt', 'log',
        'signed_power', 'sign', 'reverse', 'power', 'min', 'max', 'inverse',
        'densify', 'abs'
    ],
    'vector': [
        'vec_avg', 'vec_sum', 'vec_max', 'vec_min'
    ],
    'logical': [
        'greater_equal', 'and', 'or', 'not_equal', 'not', 'greater',
        'less_equal', 'less', 'is_nan', 'if_else', 'equal'
    ],
    'transformational': [
        'tail', 'trade_when', 'bucket'
    ]
}

CANDIDATE_ALL_OPS = []
for ops in OPERATOR_GROUPS.values():
    CANDIDATE_ALL_OPS.extend(ops)

# è¾“å‡ºç›®å½•é…ç½®
OUTPUT_DIR = 'hill_climbing_v4.7'
if not os.path.exists(OUTPUT_DIR):
    os.makedirs(OUTPUT_DIR)

# æ–‡ä»¶è·¯å¾„
BASE_CHECKPOINT_FILE = os.path.join(OUTPUT_DIR, 'checkpoint_v4.7.json')
BASE_HISTORY_FILE = os.path.join(OUTPUT_DIR, 'history_v4.7.json')
BASE_DATASET_CACHE_FILE = os.path.join(OUTPUT_DIR, 'dataset_cache_v4.7.json')
BASE_LOG_FILE = os.path.join(OUTPUT_DIR, 'hill_climbing_v4.7.log')

def setup_logging(alpha_id=None):
    log_file = BASE_LOG_FILE if not alpha_id else os.path.join(OUTPUT_DIR, f'{alpha_id}_hill_climbing_v4.7.log')
    # æ¸…é™¤æ—§çš„å¤„ç†å™¨å¹¶æ˜¾å¼å…³é—­æ–‡ä»¶å¥æŸ„
    for handler in logging.root.handlers[:]:
        try:
            handler.close()
        except:
            pass
        logging.root.removeHandler(handler)
        
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    # å¼ºåˆ¶è®©æ‰€æœ‰æ‰“å°éƒ½èƒ½çœ‹åˆ°
    logging.info("ğŸ“¢ æ—¥å¿—ç³»ç»Ÿå·²å°±ç»ª")

def send_qq_email(subject, content):
    if not EMAIL_CONFIG.get('enabled', False): return
    try:
        msg = MIMEText(content, "plain", "utf-8")
        msg["From"] = EMAIL_CONFIG['sender']
        msg["To"] = EMAIL_CONFIG['receiver']
        msg["Subject"] = Header(subject, "utf-8")
        server = smtplib.SMTP_SSL(EMAIL_CONFIG['smtp_server'], EMAIL_CONFIG['smtp_port'])
        server.login(EMAIL_CONFIG['sender'], EMAIL_CONFIG['password'])
        server.sendmail(EMAIL_CONFIG['sender'], [EMAIL_CONFIG['receiver']], msg.as_string())
        server.quit()
    except Exception as e:
        logging.error(f"é‚®ä»¶å‘é€å¤±è´¥: {e}")

def is_file_older_than_days(file_path, days):
    try:
        file_mtime = os.path.getmtime(file_path)
        file_time = datetime.fromtimestamp(file_mtime)
        return datetime.now() - file_time > timedelta(days=days)
    except: return False

def cleanup_alpha_files(alpha_id):
    files = [
        os.path.join(OUTPUT_DIR, f'{alpha_id}_checkpoint_v4.7.json'),
        os.path.join(OUTPUT_DIR, f'{alpha_id}_history_v4.7.json'),
        os.path.join(OUTPUT_DIR, f'{alpha_id}_dataset_cache_v4.7.json'),
        os.path.join(OUTPUT_DIR, f'{alpha_id}_hill_climbing_v4.7.log')
    ]
    for f in files:
        if os.path.exists(f):
            try:
                os.remove(f)
                logging.info(f"å·²æ¸…ç†: {f}")
            except: pass

# å¿½ç•¥çš„å…³é”®è¯ (é¿å…è¢«è¯¯è¯†åˆ«ä¸ºæ•°æ®å­—æ®µ)
IGNORED_TOKENS = {
    'true', 'false', 'nan', 'inf', 'filter', 'driver', 'gaussian', 'uniform', 'cauchy',
    'ignore', 'std', 'k', 'lag', 'rettype', 'scope', 'constant', 'rate', 'limit', 'sigma'
}
IGNORED_TOKENS.update(CANDIDATE_GROUPS)
IGNORED_TOKENS.update(CANDIDATE_ALL_OPS)

class BrainClient:
    def _signal_handler(self, signum, frame):
        logging.info("\nğŸ›‘ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼æ­£åœ¨å®Œæˆå½“å‰ Alpha çš„æ”¶å°¾å·¥ä½œ (æŸ“è‰²/æ”¹å/å­˜æ¡£)ï¼Œè¯·ç¨å€™...")
        self.stop_requested = True

    def __init__(self, alpha_id=None):
        self.alpha_id = alpha_id
        self.auth_lock = threading.Lock()
        self.stop_requested = False
        signal.signal(signal.SIGINT, self._signal_handler)
        
        self.sess = self._sign_in()
        self.history = self._load_history()
        self.dataset_cache = self._load_dataset_cache()
        self.last_auth_time = time.time()

    def _sign_in(self):
        cred_path = 'brain_credentials.txt'
        try:
            print(f"ğŸ“– æ­£åœ¨è¯»å–å‡­æ®æ–‡ä»¶: {cred_path}")
            with open(cred_path) as f:
                credentials = json.load(f)
            username, password = credentials
        except Exception as e:
            print(f"âŒ è¯»å–å‡­æ®å¤±è´¥: {e}")
            raise

        sess = requests.Session()
        sess.auth = HTTPBasicAuth(username, password)
        for attempt in range(5):
            try:
                print(f"ğŸ“¡ æ­£åœ¨å‘ API å‘é€ç™»å½•è¯·æ±‚ (ç¬¬ {attempt+1}/5 æ¬¡)...")
                response = sess.post('https://api.worldquantbrain.com/authentication')
                if response.status_code == 201:
                    print("âœ… API è®¤è¯æˆåŠŸï¼")
                    return sess
                else:
                    print(f"âš ï¸ ç™»å½•è¿”å›çŠ¶æ€ç : {response.status_code}, å†…å®¹: {response.text[:100]}")
            except Exception as e:
                print(f"âŒ ç™»å½•ç½‘ç»œå¼‚å¸¸: {e}")
            time.sleep(5)
        raise Exception("ç™»å½•å¤±è´¥ï¼šå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")

    def _load_history(self):
        history_file = BASE_HISTORY_FILE if not self.alpha_id else os.path.join(OUTPUT_DIR, f'{self.alpha_id}_history_v4.7.json')
        if os.path.exists(history_file):
            try:
                with open(history_file, 'r') as f: return json.load(f)
            except: return {}
        return {}

    def _load_dataset_cache(self):
        cache_file = BASE_DATASET_CACHE_FILE if not self.alpha_id else os.path.join(OUTPUT_DIR, f'{self.alpha_id}_dataset_cache_v4.7.json')
        if os.path.exists(cache_file):
            try:
                with open(cache_file, 'r') as f: return json.load(f)
            except: return {}
        return {}

    def save_history(self):
        history_file = BASE_HISTORY_FILE if not self.alpha_id else os.path.join(OUTPUT_DIR, f'{self.alpha_id}_history_v4.7.json')
        with open(history_file, 'w') as f: json.dump(self.history, f)

    def save_dataset_cache(self):
        cache_file = BASE_DATASET_CACHE_FILE if not self.alpha_id else os.path.join(OUTPUT_DIR, f'{self.alpha_id}_dataset_cache_v4.7.json')
        with open(cache_file, 'w') as f: json.dump(self.dataset_cache, f)

    def _make_request_with_retry(self, method, url, **kwargs):
        # ä» kwargs ä¸­æå–é‡è¯•æ¬¡æ•°ï¼Œé»˜è®¤ä¸º 3
        max_retries = kwargs.pop('retries', 3)

        # é»˜è®¤å¢åŠ  30 ç§’è¶…æ—¶ï¼Œé˜²æ­¢æ— é™å¡æ­»
        if 'timeout' not in kwargs:
            kwargs['timeout'] = 30

        for attempt in range(max_retries):
            try:
                resp = getattr(self.sess, method)(url, **kwargs)
                if resp.status_code == 401:
                    logging.warning(f"è¯·æ±‚è¿”å› 401ï¼Œå°è¯•é‡æ–°ç™»å½•...")
                    self.sess = self._sign_in()
                    continue
                return resp
            except Exception as e:
                # åªæœ‰å½“é‡è¯•æ¬¡æ•°å¤§äº1æ—¶æ‰æ‰“å°è­¦å‘Šï¼Œé¿å…è½»é‡çº§æ£€æŸ¥åˆ·å±
                if max_retries > 1:
                    logging.warning(f"è¯·æ±‚å¼‚å¸¸ (å°è¯• {attempt+1}/{max_retries}): {e}")
                time.sleep(2)
        return None

    def get_alpha_details(self, alpha_id):
        url = f'https://api.worldquantbrain.com/alphas/{alpha_id}'
        resp = self._make_request_with_retry('get', url)
        if resp and resp.status_code == 200:
            return resp.json()
        elif resp:
            logging.error(f"âŒ è·å–è¯¦æƒ…å¤±è´¥: Alpha {alpha_id} | çŠ¶æ€ç : {resp.status_code} | å“åº”: {resp.text[:100]}")
        else:
            logging.error(f"âŒ è·å–è¯¦æƒ…å¼‚å¸¸: Alpha {alpha_id} | è¯·æ±‚æ— è¿”å›")
        return None

    def search_dataset_for_field(self, field_name, settings):
        if field_name in self.dataset_cache:
            logging.info(f"  -> å‘½ä¸­æœ¬åœ°ç¼“å­˜: {len(self.dataset_cache[field_name])} ä¸ªå€™é€‰")
            return self.dataset_cache[field_name]

        search_scope = {
            'instrumentType': settings.get('instrumentType', 'EQUITY'),
            'region': settings.get('region', 'USA'),
            'delay': str(settings.get('delay', 1)),
            'universe': settings.get('universe', 'TOP3000')
        }

        url = "https://api.worldquantbrain.com/data-fields?" + \
              f"&instrumentType={search_scope['instrumentType']}" + \
              f"&region={search_scope['region']}" + \
              f"&delay={search_scope['delay']}" + \
              f"&universe={search_scope['universe']}" + \
              f"&limit=10&search={field_name}"

        try:
            resp = self._make_request_with_retry('get', url)
            if not resp or resp.status_code != 200: return []

            results = resp.json().get('results', [])
            target_dataset_id = None
            original_field_type = 'UNKNOWN'

            for item in results:
                if item['id'] == field_name:
                    original_field_type = item.get('type', 'UNKNOWN')
                    target_dataset_id = item['dataset']['id']
                    break

            if not target_dataset_id and results:
                target_dataset_id = results[0]['dataset']['id']
                original_field_type = results[0].get('type', 'UNKNOWN')

            if not target_dataset_id: return []

            url_ds = "https://api.worldquantbrain.com/data-fields?" + \
                     f"&instrumentType={search_scope['instrumentType']}" + \
                     f"&region={search_scope['region']}" + \
                     f"&delay={search_scope['delay']}" + \
                     f"&universe={search_scope['universe']}" + \
                     f"&dataset.id={target_dataset_id}&limit=50"

            candidates = []
            offset = 0
            while True:
                r = self._make_request_with_retry('get', url_ds + f"&offset={offset}")
                if not r or r.status_code != 200: break
                data = r.json()
                items = data.get('results', [])
                if not items: break

                for x in items:
                    if x['id'] != field_name:
                        candidates.append({'id': x['id'], 'type': x.get('type', 'UNKNOWN')})
                
                offset += 50
                if offset > 2000: break # é˜²æ­¢è¿‡å¤š

            self.dataset_cache[field_name] = candidates
            self.save_dataset_cache()
            return candidates
        except Exception as e:
            logging.error(f"æœç´¢å­—æ®µå¼‚å¸¸: {e}")
            return []

    def submit_simulation(self, simulation_data):
        url = 'https://api.worldquantbrain.com/simulations'
        time.sleep(random.uniform(0.5, 1.0))

        for attempt in range(10):
            try:
                resp = self._make_request_with_retry('post', url, json=simulation_data)
                if resp.status_code in [200, 201, 202]:
                    loc = resp.headers.get('location')
                    if not loc:
                        data = resp.json()
                        loc = data.get('url') or data.get('location') or data.get('self')
                    return loc
                
                if resp.status_code == 429:
                    wait = int(resp.headers.get("Retry-After", 10)) + random.randint(2, 5)
                    # é™é»˜ç­‰å¾…ï¼Œä¸æ‰“å°åˆ·å±æ—¥å¿—
                    time.sleep(wait)
                    continue

                logging.warning(f"æäº¤å¤±è´¥: {resp.status_code} (å°è¯• {attempt+1})")
                time.sleep(5 * (attempt + 1))
            except Exception as e:
                logging.warning(f"æäº¤å¼‚å¸¸: {e}")
                time.sleep(5)
        return None

    def wait_for_simulation(self, location_url):
        start_time = time.time()
        wait_interval = 2.0
        last_report_time = start_time
        max_wait_time = 2400  # 40 åˆ†é’Ÿæ€»è¶…æ—¶
        
        # å¢åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé˜²æ­¢å¹³å°ä»»åŠ¡å¡æ­»å¯¼è‡´è„šæœ¬æ— é™ç­‰å¾…
        while True:
            # æ£€æŸ¥æ€»ç­‰å¾…æ—¶é—´
            elapsed_total = time.time() - start_time
            if elapsed_total > max_wait_time:
                logging.error(f"   âŒ [è¶…æ—¶æ”¾å¼ƒ] è¯¥æ¨¡æ‹Ÿä»»åŠ¡å·²è¿è¡Œè¶…è¿‡ {max_wait_time/60:.1f} åˆ†é’Ÿï¼Œç–‘ä¼¼å¹³å°å¡æ­»ï¼Œå¼ºåˆ¶æ”¾å¼ƒç­‰å¾…ã€‚")
                return {"status": "ERROR", "message": "Simulation timeout after 40 minutes"}

            try:
                resp = self._make_request_with_retry('get', location_url, timeout=10)
                if not resp or resp.status_code != 200:
                    time.sleep(min(wait_interval, 5.0))
                    wait_interval *= 1.5
                    continue

                data = resp.json()
                status = data.get('status')

                # å¦‚æœç­‰å¾…è¶…è¿‡ 10 åˆ†é’Ÿï¼Œæ¯ 5 åˆ†é’ŸæŠ¥å¹³å®‰ä¸€æ¬¡
                now = time.time()
                if now - last_report_time > 300: 
                    elapsed_min = int((now - start_time) / 60)
                    logging.info(f"   [åšæŒç­‰å¾…] è¯¥æ¨¡æ‹Ÿå·²è¿è¡Œ {elapsed_min} åˆ†é’Ÿï¼Œç›®å‰çŠ¶æ€: {status}ï¼Œç»§ç»­ç­‰å¾…ç»“æœ...")
                    last_report_time = now

                # å°† WARNING ä¹Ÿè§†ä¸ºå®ŒæˆçŠ¶æ€ï¼Œå°è¯•è·å– Alpha ID
                if status in ['COMPLETED', 'COMPLETE', 'WARNING']:
                    # å¢å¼º ID æå–ï¼šä¼˜å…ˆå– alphaï¼Œå¤‡é€‰å– id (Simulation ID)ï¼Œæœ€åä» URL æˆªå–
                    alpha_id = data.get('alpha') or data.get('id')
                    
                    if status == 'WARNING':
                        msg = data.get('message', '')
                        if "reversion component" not in msg:
                            logging.warning(f"æ¨¡æ‹Ÿè¿”å› WARNING: {msg}")

                    if not alpha_id:
                        # å…œåº•ï¼šä» URL ç»“å°¾æå–æœ€åä¸€æ®µå­—ç¬¦ä¸²
                        match = re.search(r'/([^/]+)/?$', location_url)
                        if match: alpha_id = match.group(1)
                    
                    if alpha_id:
                        # æ ¸å¿ƒå¢å¼ºï¼šå¾ªç¯ç­‰å¾… Alpha ç»Ÿè®¡æ•°æ® (is å­—æ®µ) å‡ºç°
                        for attempt in range(36): 
                            details = self.get_alpha_details(alpha_id)
                            # å¿…é¡»æ‹¿åˆ° is æŠ¥è¡¨ä¸” sharpe æœ‰å€¼æ‰ç®—æˆåŠŸ
                            if details and 'is' in details and details['is'].get('sharpe') is not None:
                                return details
                            
                            # ä¼˜é›…é€€å‡ºæ£€æŸ¥
                            if getattr(self, 'stop_requested', False):
                                return details if details else data

                            logging.info(f"   [ç­‰å¾…æŠ¥è¡¨] ä»»åŠ¡ {alpha_id} å·²å®Œå·¥ï¼Œæ­£ç­‰å¾…ç»Ÿè®¡æ•°æ®ç”Ÿæˆ ({attempt+1}/36)...")
                            time.sleep(5)
                        
                        # å¦‚æœ 36 æ¬¡éƒ½æ²¡ç­‰åˆ°ï¼Œç›´æ¥æŠŠå¸¦ ID çš„åŸå§‹ data è¿”å›ï¼Œè®© _process_result å»æœ€åè¡¥æ•‘
                        return data
                    return data
                
                if status in ['ERROR', 'FAIL']:
                    logging.error(f"   âŒ æ¨¡æ‹Ÿä»»åŠ¡å¤±è´¥! çŠ¶æ€: {status} | æ¶ˆæ¯: {data.get('message')}")
                    return data
                
                time.sleep(min(wait_interval, 5.0))
                wait_interval *= 1.5
            except Exception as e:
                logging.warning(f"ç­‰å¾…ç»“æœå¼‚å¸¸ (ç½‘ç»œæŠ–åŠ¨?): {e}")
                time.sleep(5.0)

    def check_factory_shape(self, alpha_id):
        """
        å¢å¼ºç‰ˆå‚å­—å‹æ£€æŸ¥ï¼šæ•´åˆå¹´åº¦ç»Ÿè®¡ä¸ PNL è¯¦æƒ…
        """
        try:
            # 1. æ£€æŸ¥å¹´åº¦ç»Ÿè®¡ (Yearly Stats)
            url_yearly = f"https://api.worldquantbrain.com/alphas/{alpha_id}/recordsets/yearly-stats"
            json_yearly = None
            for _ in range(3):
                resp = self._make_request_with_retry('get', url_yearly)
                if resp and resp.status_code == 200 and resp.text.strip():
                    try:
                        temp = resp.json()
                        if temp.get('records'):
                            json_yearly = temp
                            break
                    except: pass
                time.sleep(2)

            if json_yearly:
                records = json_yearly.get('records', [])
                non_zero_sharpe_count = sum(1 for r in records if len(r) > 6 and r[6] is not None and abs(float(r[6])) > 1e-6)
                if non_zero_sharpe_count > 0 and non_zero_sharpe_count < 8:
                    logging.info(f"  ğŸŸ£ [å‚å­—å‹] æœ‰æ•ˆå¹´ä»½ä¸è¶³ 8 å¹´ ({non_zero_sharpe_count})")
                    return True

            # 2. æ£€æŸ¥ PNL è¯¦æƒ… (é’ˆå¯¹é‚£ç§çœ‹ä¼¼å¹´ä»½å¤šä½†æœ«ç«¯å¹³èººçš„ Alpha)
            url_pnl = f"https://api.worldquantbrain.com/alphas/{alpha_id}/recordsets/pnl"
            for _ in range(3):
                resp_pnl = self._make_request_with_retry('get', url_pnl)
                if resp_pnl and resp_pnl.status_code == 200:
                    data_pnl = resp_pnl.json().get('records', [])
                    if data_pnl:
                        if not self._check_consecutive_pnl_values(alpha_id, data_pnl):
                            return True
                        break
                time.sleep(2)

            return False

        except Exception as e:
            logging.error(f"å¢å¼ºå‚å­—å‹æ£€æŸ¥å¼‚å¸¸: {e}")
            return False

    def set_alpha_color(self, alpha_id, color):
        """è®¾ç½® Alpha é¢œè‰²"""
        url = f'https://api.worldquantbrain.com/alphas/{alpha_id}'
        try:
            self._make_request_with_retry('patch', url, json={'color': color})
        except Exception as e:
            logging.warning(f"è®¾ç½®é¢œè‰²å¤±è´¥: {e}")

    def set_alpha_name(self, alpha_id, name):
        """è®¾ç½® Alpha åç§°"""
        url = f'https://api.worldquantbrain.com/alphas/{alpha_id}'
        try:
            self._make_request_with_retry('patch', url, json={'name': name})
        except Exception as e:
            logging.warning(f"è®¾ç½®åç§°å¤±è´¥: {e}")

    def get_product_correlation(self, alpha_id, max_attempts=40):
        """è·å– Alpha çš„ Product Correlation (PC) - å¼ºåŠ›å–å›ç‰ˆ"""
        url = f"https://api.worldquantbrain.com/alphas/{alpha_id}/correlations/prod"
        for i in range(max_attempts):
            try:
                resp = self._make_request_with_retry('get', url, timeout=15)
                if resp and resp.status_code == 200:
                    data = resp.json()
                    if "max" in data:
                        return float(data["max"])
                elif resp and resp.status_code == 404:
                    pass
            except: pass
            
            if max_attempts > 5 and i % 5 == 0:
                logging.info(f"   [PCç­‰å¾…] æ­£åœ¨ç­‰å¾… Alpha {alpha_id} çš„ PC æ•°æ® (ç¬¬ {i+1}/{max_attempts} æ¬¡æŸ¥è¯¢)...")
            time.sleep(30)
            
        logging.warning(f"   âŒ [PCå¤±è´¥] ç»è¿‡ {max_attempts} æ¬¡å°è¯•ä»æ— æ³•è·å– PC: {alpha_id}")
        return None

    def get_alpha_pnl_df(self, alpha_id):
        """è·å–å•ä¸ª Alpha çš„ PnL å¹¶è¿”å› DataFrame (å¢å¼ºè¯Šæ–­ç‰ˆ)"""
        url = f"https://api.worldquantbrain.com/alphas/{alpha_id}/recordsets/pnl"
        try:
            resp = self._make_request_with_retry('get', url, retries=2)
            if resp and resp.status_code == 200:
                try:
                    data = resp.json()
                    if 'records' in data and data['records']:
                        df = pd.DataFrame(data['records'], columns=[item['name'] for item in data['schema']['properties']])
                        df['date'] = pd.to_datetime(df['date'])
                        df.set_index('date', inplace=True)
                        return df[['pnl']].rename(columns={'pnl': alpha_id})
                    else:
                        # æ•°æ®ä¸ºç©ºï¼Œé€šå¸¸æ˜¯å› ä¸ºæ¨¡æ‹Ÿå°šæœªå®Œå…¨ç»“æŸ
                        return None
                except json.JSONDecodeError:
                    return None
            elif resp:
                if resp.status_code != 404: # å¿½ç•¥å¸¸è§çš„ 404 (æ•°æ®æœªç”Ÿæˆ)
                    logging.warning(f"âš ï¸ è·å– Alpha {alpha_id} PnL å¤±è´¥: HTTP {resp.status_code}")
            return None
        except Exception as e:
            logging.warning(f"âš ï¸ è·å– Alpha {alpha_id} PnL å¼‚å¸¸: {e}")
        return None

    def download_os_pnl_pool(self):
        """å¢é‡åŒæ­¥ OS Alpha çš„ PnL æ•°æ®"""
        logging.info("ğŸ“¡ æ­£åœ¨åŒæ­¥ OS åº“ Alpha åˆ—è¡¨...")
        all_os_alphas = []
        offset = 0
        while True:
            try:
                url = f"https://api.worldquantbrain.com/users/self/alphas?stage=OS&limit=100&offset={offset}&order=-dateSubmitted"
                resp = self._make_request_with_retry('get', url)
                if not resp or resp.status_code != 200: break
                data = resp.json()
                results = data.get('results', [])
                if not results: break
                all_os_alphas.extend(results)
                if len(results) < 100: break
                offset += 100
            except Exception as e:
                logging.warning(f"åŒæ­¥ OS åˆ—è¡¨å‡ºé”™: {e}")
                break

        if not all_os_alphas:
            logging.warning("âš ï¸ æœªèƒ½è·å–åˆ°ä»»ä½• OS Alpha")
            return pd.DataFrame()

        server_ids = [a['id'] for a in all_os_alphas]
        print(f"âœ… åˆ—è¡¨åŒæ­¥å®Œæˆï¼æœåŠ¡å™¨å…±æœ‰ {len(server_ids)} ä¸ª OS Alphaã€‚")

        # --- å¢é‡é€»è¾‘å¼€å§‹ ---
        pickle_path = os.path.join(OUTPUT_DIR, 'os_pnl_pool.pickle')
        local_pool = pd.DataFrame()
        if os.path.exists(pickle_path):
            try:
                local_pool = pd.read_pickle(pickle_path)
                # åªä¿ç•™æœåŠ¡å™¨ä¸Šä¾ç„¶å­˜åœ¨çš„ ID
                existing_ids = [aid for aid in local_pool.columns if aid in server_ids]
                local_pool = local_pool[existing_ids]
                logging.info(f"ğŸ’¾ å·²åŠ è½½æœ¬åœ°ç¼“å­˜: {len(existing_ids)} ä¸ª Alpha")
            except Exception as e:
                logging.warning(f"è¯»å–æœ¬åœ°ç¼“å­˜å¤±è´¥: {e}")

        # æ‰¾å‡ºéœ€è¦æ–°ä¸‹è½½çš„ ID
        need_download_ids = [aid for aid in server_ids if aid not in local_pool.columns]
        
        if not need_download_ids:
            print(f"âœ¨ æœ¬åœ°ç¼“å­˜å·²æ˜¯æœ€æ–°çš„ï¼Œå…±æœ‰ {local_pool.shape[1]} ä¸ª Alphaã€‚")
            return local_pool

        print(f"â³ å‘ç° {len(need_download_ids)} ä¸ªæ–° Alphaï¼Œå¼€å§‹å¢é‡ä¸‹è½½...")
        
        new_pnl_list = []
        with ThreadPoolExecutor(max_workers=2) as executor:
            future_to_id = {executor.submit(self.get_alpha_pnl_df, aid): aid for aid in need_download_ids}
            completed_count = 0
            for future in as_completed(future_to_id):
                res = future.result()
                if res is not None:
                    new_pnl_list.append(res)
                
                completed_count += 1
                if completed_count % 10 == 0 or completed_count == len(need_download_ids):
                    print(f"   [å¢é‡ä¸‹è½½è¿›åº¦] {completed_count}/{len(need_download_ids)} (å·²æˆåŠŸæ•è· {len(new_pnl_list)} ä¸ª)")
                time.sleep(random.uniform(0.1, 0.2))
        
        # åˆå¹¶æ–°æ—§æ•°æ®
        if new_pnl_list:
            new_df = pd.concat(new_pnl_list, axis=1)
            if not local_pool.empty:
                full_pool = pd.concat([local_pool, new_df], axis=1)
            else:
                full_pool = new_df
            
            full_pool.sort_index(inplace=True)
            # ä¿å­˜æ›´æ–°åçš„æ± 
            full_pool.to_pickle(pickle_path)
            print(f"âœ¨ å¢é‡åŒæ­¥æˆåŠŸï¼å½“å‰ PnL æ± å…±æœ‰ {full_pool.shape[1]} ä¸ª Alpha ç”¨äº SC è®¡ç®—ã€‚")
            return full_pool
        
        return local_pool

    def calculate_sc_locally(self, alpha_id, os_pool):
        """åœ¨æœ¬åœ°è®¡ç®— Alpha ä¸ OS æ± çš„æœ€å¤§ç›¸å…³æ€§"""
        if os_pool.empty: return 0.0
        
        new_pnl = self.get_alpha_pnl_df(alpha_id)
        if new_pnl is None: return None
        
        # å¯¹é½æ•°æ®ï¼šå–æœ€è¿‘ 4 å¹´æ•°æ® (å‚è€ƒ C3 é€»è¾‘)
        combined = pd.concat([os_pool, new_pnl], axis=1)
        combined = combined.ffill()
        rets = combined.diff()
        
        if rets.empty: return 0.0
        
        # åªå–æœ€è¿‘ä¸€æ®µæ—¶æœŸçš„æ”¶ç›Šç‡è¿›è¡Œç›¸å…³æ€§è®¡ç®—
        last_date = rets.index.max()
        rets = rets[rets.index > last_date - pd.DateOffset(years=4)]
        
        corr_matrix = rets.corr()
        if alpha_id in corr_matrix.columns:
            # æå–è¯¥ Alpha ä¸æ± ä¸­å…¶ä»– Alpha çš„ç›¸å…³æ€§
            sc_series = corr_matrix[alpha_id].drop(alpha_id)
            return float(sc_series.max())
        return 0.0

    def set_alpha_color(self, alpha_id, color):
        """è®¾ç½® Alpha é¢œè‰²"""
        url = f'https://api.worldquantbrain.com/alphas/{alpha_id}'
        try:
            self._make_request_with_retry('patch', url, json={'color': color})
        except Exception as e:
            logging.warning(f"è®¾ç½®é¢œè‰²å¤±è´¥: {e}")

    def set_alpha_name(self, alpha_id, name):
        """è®¾ç½® Alpha åç§°"""
        url = f'https://api.worldquantbrain.com/alphas/{alpha_id}'
        try:
            self._make_request_with_retry('patch', url, json={'name': name})
        except Exception as e:
            logging.warning(f"è®¾ç½®åç§°å¤±è´¥: {e}")

    def get_product_correlation(self, alpha_id, max_attempts=40):
        """è·å– Alpha çš„ Product Correlation (PC) - å¼ºåŠ›å–å›ç‰ˆ"""
        url = f"https://api.worldquantbrain.com/alphas/{alpha_id}/correlations/prod"
        for i in range(max_attempts):
            try:
                resp = self._make_request_with_retry('get', url, timeout=15)
                if resp and resp.status_code == 200:
                    data = resp.json()
                    if "max" in data:
                        return float(data["max"])
                elif resp and resp.status_code == 404:
                    pass
            except: pass
            
            if max_attempts > 5 and i % 5 == 0:
                logging.info(f"   [PCç­‰å¾…] æ­£åœ¨ç­‰å¾… Alpha {alpha_id} çš„ PC æ•°æ® (ç¬¬ {i+1}/{max_attempts} æ¬¡æŸ¥è¯¢)...")
            time.sleep(30)
            
        logging.warning(f"   âŒ [PCå¤±è´¥] ç»è¿‡ {max_attempts} æ¬¡å°è¯•ä»æ— æ³•è·å– PC: {alpha_id}")
        return None

    def get_self_correlation(self, alpha_id, max_attempts=20):
        """è·å– Alpha çš„ Self Correlation (SC) - å¼ºåŠ›å–å›ç‰ˆ"""
        url = f"https://api.worldquantbrain.com/alphas/{alpha_id}/correlations/self"
        for i in range(max_attempts):
            try:
                resp = self._make_request_with_retry('get', url, timeout=15)
                if resp and resp.status_code == 200:
                    data = resp.json()
                    if "max" in data:
                        return float(data["max"])
            except: pass
            time.sleep(30)
        return None

    def _check_consecutive_pnl_values(self, alpha_id, data, required_streak=250):
        """
        æ£€æŸ¥æ˜¯å¦æœ‰è¿ç»­ required_streak å¤©çš„ç›¸åŒéé›¶å€¼ (å‚å­—å‹æ ¸å¿ƒç‰¹å¾)
        """
        if not data or len(data) < required_streak:
            return True # æ•°æ®ä¸è¶³ï¼Œè§†ä¸ºé€šè¿‡

        pnl_values = [row[1] for row in data if len(row) >= 2]
        if not pnl_values: return True
        
        if all(v == 0 for v in pnl_values):
            return False # å…¨ 0 ä¹Ÿæ˜¯æ— æ•ˆ

        # æ£€æŸ¥æœ«ç«¯ç¨³å®šæ€§ (ä»åå¾€å‰æŸ¥)
        end_streak_count = 0
        end_streak_value = pnl_values[-1]
        for i in range(len(pnl_values)-1, -1, -1):
            if pnl_values[i] == end_streak_value:
                end_streak_count += 1
            else:
                break
        
        if end_streak_count >= required_streak:
            logging.info(f"  ğŸŸ£ [å‚å­—å‹] æœ«ç«¯è¿ç»­ {end_streak_count} å¤©æ•°å€¼ç›¸åŒ: {end_streak_value}")
            return False

        # æ£€æŸ¥å…¨å±€è¿ç»­æ€§
        curr_count = 0
        curr_val = None
        for v in pnl_values:
            if v != 0:
                if v == curr_val:
                    curr_count += 1
                else:
                    curr_val = v
                    curr_count = 1
            else:
                curr_val = None
                curr_count = 0
            
            if curr_count >= required_streak:
                logging.info(f"  ğŸŸ£ [å‚å­—å‹] å…¨å±€æ£€æµ‹åˆ°è¿ç»­ {curr_count} å¤©ç›¸åŒéé›¶å€¼")
                return False
        return True

class SmartExpression:
    def __init__(self, expression, settings, client):
        self.original_expr = expression
        self.settings = settings
        self.client = client
        self.tokens = []
        self.data_fields_cache = {}
        self._parse()

    def _parse(self):
        # ç›´æ¥ä½¿ç”¨åŸå§‹å…¬å¼è§£æï¼Œç¡®ä¿ç´¢å¼•ç»å¯¹å‡†ç¡®
        pattern = re.compile(r'([a-zA-Z_][a-zA-Z0-9_.]*)|(-?\d+\.?\d*)')
        self.tokens = []
        unique_data_fields_list = []
        seen_fields = set()

        current_idx = 0
        while current_idx < len(self.original_expr):
            match = pattern.search(self.original_expr, current_idx)
            if not match: break
            
            text = match.group()
            start, end = match.span()
            token_type = 'unknown'

            if re.match(r'^-?\d+\.?\d*$', text):
                token_type = 'number'
            elif text in CANDIDATE_ALL_OPS:
                token_type = 'operator'
            elif text in CANDIDATE_GROUPS:
                token_type = 'group'
            elif text.lower() in IGNORED_TOKENS:
                token_type = 'keyword'
            # è¯†åˆ«ç®—å­æ§åˆ¶å‚æ•°ï¼Œé˜²æ­¢è¯¯å½“æˆæ•°æ®å­—æ®µä¼˜åŒ–
            elif text.startswith('lambda_') or text == 'target_tvr' or text.endswith('_tvr'):
                token_type = 'parameter'
            else:
                token_type = 'data_field'
                if text not in seen_fields:
                    unique_data_fields_list.append(text)
                    seen_fields.add(text)

            self.tokens.append({'text': text, 'type': token_type, 'start': start, 'end': end})
            current_idx = end

        total_data_instances = len([t for t in self.tokens if t['type'] == 'data_field'])
        logging.info(f"è¯†åˆ«åˆ° {len(unique_data_fields_list)} ç§æ•°æ®å­—æ®µ (å…± {total_data_instances} ä¸ªä¼˜åŒ–ä½ç½®): {unique_data_fields_list}")
        
        for i, field in enumerate(unique_data_fields_list):
            logging.info(f"[{i + 1}/{len(unique_data_fields_list)}] æ­£åœ¨æœç´¢å­—æ®µ '{field}'...")
            # å…ˆå°è¯•ä»ç¼“å­˜è·å–
            cached_cands = self.data_fields_cache.get(field)
            if cached_cands:
                # è·å–åŸå§‹å­—æ®µç±»å‹
                original_field_type = 'UNKNOWN'
                for cached_field in cached_cands:
                    if cached_field.get('id') == field and isinstance(cached_field, dict):
                        original_field_type = cached_field.get('type', 'UNKNOWN')
                        break

                # æ ¹æ®åŸå§‹å­—æ®µç±»å‹è¿‡æ»¤ç¼“å­˜ä¸­çš„å€™é€‰å­—æ®µ
                if original_field_type != 'UNKNOWN':
                    filtered_cands = [cand for cand in cached_cands if
                                      isinstance(cand, dict) and cand.get('type') == original_field_type]
                    # æ›´æ–°ç¼“å­˜
                    self.data_fields_cache[field] = filtered_cands
                    cached_cands = filtered_cands

                # æ˜¾ç¤ºç¼“å­˜ä¸­çš„å€™é€‰å­—æ®µæ•°é‡å’Œç±»å‹ä¿¡æ¯
                type_counts = {}
                for cand in cached_cands:
                    field_type = cand.get('type', 'UNKNOWN') if isinstance(cand, dict) else 'UNKNOWN'
                    type_counts[field_type] = type_counts.get(field_type, 0) + 1
                type_info = ", ".join([f"{count}ä¸ª{ftype}" for ftype, count in type_counts.items()])
                logging.info(f"  -> å‘½ä¸­æœ¬åœ°ç¼“å­˜: {len(cached_cands)} ä¸ªå€™é€‰å­—æ®µ ({type_info})")
            else:
                # ç¼“å­˜ä¸­æ²¡æœ‰åˆ™ä»APIè·å–
                cands = self.client.search_dataset_for_field(field, self.settings)
                if cands:
                    self.data_fields_cache[field] = cands
                    # æ˜¾ç¤ºæ‰¾åˆ°çš„å€™é€‰å­—æ®µæ•°é‡å’Œç±»å‹ä¿¡æ¯
                    type_counts = {}
                    for cand in cands:
                        field_type = cand.get('type', 'UNKNOWN') if isinstance(cand, dict) else 'UNKNOWN'
                        type_counts[field_type] = type_counts.get(field_type, 0) + 1
                    type_info = ", ".join([f"{count}ä¸ª{ftype}" for ftype, count in type_counts.items()])
                    logging.info(f"  -> æ‰¾åˆ° {len(cands)} ä¸ªå€™é€‰å­—æ®µ ({type_info})")
                else:
                    logging.warning(f"å­—æ®µ '{field}' æœªæ‰¾åˆ°å€™é€‰ï¼Œä½†å°†ä¿ç•™å…¶åœ¨ä¼˜åŒ–åˆ—è¡¨ä¸­çš„ä½ç½®")
                    # ä¿æŒ token['type'] = 'data_field' ä¸å˜ï¼Œç¡®ä¿ç´¢å¼•ç¨³å®šæ€§

    def _get_operator_group(self, operator_name):
        """ç¡®å®šè¿ç®—ç¬¦å±äºå“ªä¸ªç»„"""
        for group_name, operators in OPERATOR_GROUPS.items():
            if operator_name in operators:
                return group_name
        return None

    def generate_neighbors(self, target_type, target_index):
        """ç”Ÿæˆå˜ä½“ (å›å½’ v4.4 ç¨³å¥ç‰ˆ)"""
        # ç»Ÿä¸€å¤„ç† time_window å’Œ number æœç´¢ç±»å‹
        actual_search_type = 'number' if target_type == 'time_window' else target_type
        
        # ç›´æ¥æ‰¾åˆ°æ‰€æœ‰è¯¥ç±»å‹çš„ Token
        candidates_indices = []
        for idx, t in enumerate(self.tokens):
            if t['type'] == actual_search_type:
                # æ’é™¤ç®—å­å†…éƒ¨å‚æ•° (lambda_, target_tvr)
                if t['text'].startswith('lambda_') or 'tvr' in t['text']:
                    continue
                candidates_indices.append(idx)
        
        if not candidates_indices or target_index >= len(candidates_indices):
            return []

        token_idx = candidates_indices[target_index]
        token = self.tokens[token_idx]
        old_text = token['text']

        pool = []
        if target_type == 'data_field':
            pool = self.data_fields_cache.get(old_text, [])
            if not pool:
                # ç­–ç•¥ 1: åŸåæœç´¢
                pool = self.client.search_dataset_for_field(old_text, self.settings)
                
                # ç­–ç•¥ 2: å‰¥ç¦»åç¼€æ¨¡ç³Šæœç´¢
                if not pool and '_' in old_text:
                    parts = old_text.split('_')
                    if len(parts) > 1:
                        short_name = '_'.join(parts[:-1])
                        logging.info(f"  -> å­—æ®µ '{old_text}' æœç´¢æ— æœï¼Œå°è¯•å‰ç¼€æœç´¢: {short_name}")
                        pool = self.client.search_dataset_for_field(short_name, self.settings)
                
                # ç­–ç•¥ 3: é€šç”¨è¡¥æ•‘
                if not pool:
                    if 'price' in old_text.lower():
                        pool = self.client.search_dataset_for_field('pv_price', self.settings)
                    elif 'volume' in old_text.lower():
                        pool = self.client.search_dataset_for_field('pv_volume', self.settings)

                if pool: self.data_fields_cache[old_text] = pool
            
            if pool:
                logging.info(f"  -> æ‰¾åˆ° {len(pool)} ä¸ªå€™é€‰å­—æ®µ")
            else:
                logging.warning(f"å­—æ®µ '{old_text}' ä»æœªæ‰¾åˆ°å€™é€‰ï¼Œå°†è·³è¿‡ä¼˜åŒ–")
                return []
        elif target_type in ['number', 'time_window']:
            # ç‰¹æ®Šå¤„ç†ï¼šå›ºå®šæ•°å€¼-1ä¸åº”è¢«æ›¿æ¢
            if old_text == '-1':
                logging.info(f"  -> æ£€æµ‹åˆ°å›ºå®šæ•°å€¼ '{old_text}'ï¼Œä¸å‚ä¸ä¼˜åŒ–")
                return []

            # æ™ºèƒ½åˆ¤æ–­ï¼šæ•´æ•°ä¸”>=1è§†ä¸ºå¤©æ•°ï¼Œå¦åˆ™è§†ä¸ºç³»æ•°
            if '.' not in old_text and float(old_text) >= 1:
                pool = [str(x) for x in CANDIDATE_DAYS]
            else:
                pool = [str(x) for x in CANDIDATE_NUMBERS]
        elif target_type == 'group':
            pool = CANDIDATE_GROUPS
        elif target_type == 'operator':
            # åªåœ¨åŒä¸€ç»„å†…æŸ¥æ‰¾æ›¿ä»£è¿ç®—ç¬¦
            operator_group = self._get_operator_group(old_text)
            if operator_group:
                pool = OPERATOR_GROUPS[operator_group]
                logging.info(f"  -> è¿ç®—ç¬¦ '{old_text}' å±äº '{operator_group}' ç»„ï¼Œå°†åœ¨è¯¥ç»„å†…æŸ¥æ‰¾æ›¿ä»£")
            else:
                # å¦‚æœæ‰¾ä¸åˆ°æ‰€å±ç»„ï¼Œåˆ™åœ¨æ•´ä¸ªè¿ç®—ç¬¦æ± ä¸­æŸ¥æ‰¾
                pool = CANDIDATE_ALL_OPS
                logging.warning(f"  -> æœªæ‰¾åˆ°è¿ç®—ç¬¦ '{old_text}' çš„æ‰€å±ç»„ï¼Œå°†åœ¨æ•´ä¸ªè¿ç®—ç¬¦æ± ä¸­æŸ¥æ‰¾æ›¿ä»£")

        # å¤„ç†å€™é€‰æ± ï¼Œç¡®ä¿æ­£ç¡®æå–å­—æ®µID
        processed_pool = []
        for x in pool:
            if isinstance(x, dict):
                processed_pool.append(x['id'])
            else:
                processed_pool.append(str(x))

        # è¿‡æ»¤æ‰ä¸åŸæ–‡æœ¬ç›¸åŒçš„é¡¹
        filtered_pool = [x for x in processed_pool if x != old_text]

        if not filtered_pool:
            return []

        results = []
        for cand in filtered_pool:
            new_expr = self.original_expr[:token['start']] + cand + self.original_expr[token['end']:]
            results.append(new_expr)

        return list(set(results))


class AsyncOptimizer:
    def _signal_handler(self, signum, frame):
        logging.info("\nğŸ›‘ æ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼æ­£åœ¨å®Œæˆå½“å‰ Alpha çš„æ”¶å°¾å·¥ä½œ (æŸ“è‰²/æ”¹å/å­˜æ¡£)ï¼Œè¯·ç¨å€™...")
        self.stop_requested = True

    def __init__(self, alpha_id=None):
        self.alpha_id = alpha_id
        self.auth_lock = threading.Lock() # æ·»åŠ ç™»å½•é”
        self.score_lock = threading.Lock() # æ¢å¤åˆ†æ•°é”
        self.stop_requested = False # ä¼˜é›…é€€å‡ºæ ‡å¿—ä½
        
        # æ³¨å†Œä¿¡å·å¤„ç†å™¨ (é˜²æ­¢é‡å¤æ³¨å†Œæˆ–æŠ¥é”™)
        try:
            signal.signal(signal.SIGINT, self._signal_handler)
        except Exception:
            pass

        # åœ¨æ¨¡å¼1ä¸‹ï¼Œå…ˆåˆ é™¤æ—§æ–‡ä»¶
        if RUN_MODE == 1:
            print("ğŸ§¹ æ­£åœ¨æ¸…ç†æ—§çš„æ—¥å¿—å’Œæ£€æŸ¥ç‚¹æ–‡ä»¶...")
            self._cleanup_old_files()

        print("ğŸ”‘ æ­£åœ¨å°è¯•ç™»å½• WorldQuant Brain å¹³å°...")
        self.client = BrainClient(alpha_id)
        print("ğŸ”“ ç™»å½•æˆåŠŸï¼")
        
        # --- v4.6 æ–°å¢ï¼šåˆå§‹åŒ– PnL æ±  ---
        self.os_pool = self.client.download_os_pnl_pool()
        # -----------------------------

        self.best_expr = None
        self.best_score = -9999
        self.best_base_score = -9999  # æ–°å¢ï¼šè®°å½•ä¸å« PC å¥–æƒ©çš„åŸºç¡€åˆ†æ•°
        self.settings = None
        self.history_cache = {}
        self.best_alpha_id = None  # æ·»åŠ è·Ÿè¸ªæœ€ä½³Alpha IDçš„å±æ€§
        self.initial_score = None  # æ·»åŠ åˆå§‹åˆ†æ•°å±æ€§
        self.initial_alpha_id = None  # æ·»åŠ åˆå§‹Alpha IDå±æ€§
        self.best_pc = None  # è®°å½•å½“å‰æœ€ä¼˜è§£çš„ PC å€¼ (Noneè¡¨ç¤ºå°šæœªè·å–)
        self.best_stats = {}  # è®°å½•æœ€ä¼˜è§£çš„è¯¦ç»†ç»Ÿè®¡æŒ‡æ ‡
        # æ–°å¢ï¼šè®°å½•å½“å‰ä¼˜åŒ–ä½ç½®ï¼ˆåŒ…æ‹¬å­—æ®µå’Œæ‰¹æ¬¡ï¼‰
        self.current_position = {
            'data_field': START_OPTIMIZATION_FROM['data_field'],
            'time_window': START_OPTIMIZATION_FROM['time_window'],
            'number': START_OPTIMIZATION_FROM['number'],
            'group': START_OPTIMIZATION_FROM['group'],
            'operator': START_OPTIMIZATION_FROM['operator'],
            'batch_offset': 0,  # æ‰¹æ¬¡åç§»é‡
            'neutralization': 0,  # ä¸­æ€§åŒ–å‚æ•°ä¼˜åŒ–ä½ç½®
            'decay': 0  # è¡°å‡å‚æ•°ä¼˜åŒ–ä½ç½®
        }

    def _cleanup_old_files(self):
        """æ¸…ç†æ—§çš„æ£€æŸ¥ç‚¹å’Œæ—¥å¿—æ–‡ä»¶"""
        logging.info(f"æ¸…ç†æ—§æ–‡ä»¶ (æ‰«æç›®å½•: {OUTPUT_DIR})...")
        patterns = [r'.*_v4\.[67]\.json$', r'.*_v4\.[67]\.log$', r'checkpoint.*\.json$', r'history.*\.json$']
        try:
            for fname in os.listdir(OUTPUT_DIR):
                if any(re.match(p, fname) for p in patterns):
                    full_path = os.path.join(OUTPUT_DIR, fname)
                    if is_file_older_than_days(full_path, 2):
                        try:
                            # å°è¯•å…³é—­å¥æŸ„
                            for handler in logging.root.handlers[:]:
                                handler.close()
                                logging.root.removeHandler(handler)
                            os.remove(full_path)
                            logging.info(f"å·²åˆ é™¤æ—§æ–‡ä»¶: {full_path}")
                        except: pass
        except Exception as e:
            logging.warning(f"æ¸…ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")

        # é‡æ–°åˆå§‹åŒ–æ—¥å¿—é…ç½®
        setup_logging(self.alpha_id)

    def calculate_sc_locally(self, alpha_id, os_pool):
        """ä»£ç†è°ƒç”¨å®¢æˆ·ç«¯çš„æœ¬åœ°SCè®¡ç®—é€»è¾‘"""
        return self.client.calculate_sc_locally(alpha_id, os_pool)

    def calculate_sc_penalty(self, sc_val):
        """è®¡ç®— SC æƒ©ç½šåˆ† (å¹³æ»‘é€’å¢ç‰ˆ)"""
        if sc_val is None or sc_val <= 0.7:
            return 0
        
        # é˜¶æ¢¯ 1: 0.7 - 0.72 (10å€)
        if sc_val <= 0.72:
            return (0.7 - sc_val) * 10
        # é˜¶æ¢¯ 2: 0.72 - 0.80 (30å€)
        elif sc_val <= 0.80:
            return (0.7 - sc_val) * 30
        # é˜¶æ¢¯ 3: > 0.80 (50å€ - å·¨ç—›ä½†ç»™æ´»è·¯)
        else:
            return (0.7 - sc_val) * 50

    def _extract_scores_from_name(self, name):
        """ä» Alpha åå­—ä¸­æå– PC å’Œ SC å€¼"""
        pc_val, sc_val = None, None
        if not name: return pc_val, sc_val
        
        # åŒ¹é… PC (-?\d+(?:\.\d+)?)
        pc_match = re.search(r'PC(-?\d+(?:\.\d+)?)', name)
        if pc_match: pc_val = float(pc_match.group(1))
        
        # åŒ¹é… SC (-?\d+(?:\.\d+)?)
        sc_match = re.search(r'SC(-?\d+(?:\.\d+)?)', name)
        if sc_match: sc_val = float(sc_match.group(1))
        
        return pc_val, sc_val

    def load_checkpoint(self, alpha_id):
        """ä¸ºç‰¹å®šAlpha IDåŠ è½½æ£€æŸ¥ç‚¹"""
        checkpoint_file = os.path.join(OUTPUT_DIR, f'{alpha_id}_checkpoint_v4.7.json')
        if os.path.exists(checkpoint_file):
            try:
                with open(checkpoint_file, 'r') as f:
                    data = json.load(f)
                    
                    # å¼ºæ ¡éªŒï¼šæ¯”å¯¹ initial_alpha_id è€Œä¸æ˜¯å½“å‰æœ€ä¼˜ alpha_id
                    # è¿™æ ·å³ä½¿çˆ¬å±±è¿‡ç¨‹ä¸­ ID å˜äº†ï¼Œåªè¦æ˜¯åŒä¸€ä¸ªèµ·å§‹ä»»åŠ¡ï¼Œå°±èƒ½ç»­çˆ¬
                    saved_initial_id = data.get('initial_alpha_id')
                    
                    # å…¼å®¹æ—§ç‰ˆ checkpoint (å¦‚æœæ²¡æœ‰ initial_alpha_idï¼Œå°è¯•ç”¨ alpha_id å…œåº•ï¼Œä½†å¯èƒ½ä¼šè¯¯åˆ¤)
                    if not saved_initial_id:
                        saved_initial_id = data.get('alpha_id')

                    if saved_initial_id != alpha_id:
                        logging.warning(f"âš ï¸ æ£€æŸ¥ç‚¹åˆå§‹ ID ({saved_initial_id}) ä¸ç›®æ ‡ ID ({alpha_id}) ä¸åŒ¹é…ï¼Œå°†é‡ç½®è¿›åº¦ï¼")
                        return False

                    self.best_expr = data['expr']
                    self.best_score = data['score']
                    self.best_base_score = data.get('base_score', self.best_score)
                    self.settings = data['settings']
                    self.best_alpha_id = data.get('alpha_id', None)
                    self.initial_score = data.get('initial_score', None)
                    self.initial_alpha_id = data.get('initial_alpha_id', None)
                    self.best_pc = data.get('best_pc', None) # åŠ è½½ä¿å­˜çš„ PC å€¼
                    self.best_stats = data.get('best_stats', {})
                    # åŠ è½½å½“å‰ä¼˜åŒ–ä½ç½®ï¼ˆåŒ…æ‹¬å­—æ®µå’Œæ‰¹æ¬¡ï¼‰
                    self.current_position = data.get('current_position', self.current_position)
                    logging.info(f"æ–­ç‚¹ç»­ä¼ : Score={self.best_score}, Alpha ID={self.best_alpha_id}, PC={self.best_pc}")
                    return True
            except Exception as e:
                logging.error(f"åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}")
                pass
        return False

    def save_checkpoint(self, alpha_id):
        """ä¸ºç‰¹å®šAlpha IDä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_file = os.path.join(OUTPUT_DIR, f'{alpha_id}_checkpoint_v4.7.json')
        with open(checkpoint_file, 'w') as f:
            json.dump({
                'expr': self.best_expr,
                'score': self.best_score,
                'base_score': self.best_base_score,
                'settings': self.settings,
                'alpha_id': self.best_alpha_id,
                'best_pc': self.best_pc, # ä¿å­˜å½“å‰ PC å€¼
                'best_stats': self.best_stats,
                'target_alpha_ids': TARGET_ALPHA_IDS,
                'initial_score': self.initial_score,
                'initial_alpha_id': self.initial_alpha_id, # <--- æ ¸å¿ƒä¿®å¤ï¼šå¿…é¡»å­˜è¿™ä¸ªï¼
                'current_position': self.current_position
            }, f)





    def evaluate_batch(self, expr_list, settings=None):
        """åŒæ­¥æ‰¹å¤„ç†è¯„ä¼° (ä¿®å¤ï¼šå°† Settings çº³å…¥ç¼“å­˜é”®)"""
        if settings is None:
            settings = self.settings

        to_run = []
        results = {}

        for expr in expr_list:
            # æ ¸å¿ƒä¿®å¤ï¼šç¼“å­˜é”®åº”åŒ…å« settings ä»¥æ”¯æŒå‚æ•°ä¼˜åŒ–å›æµ‹
            cache_payload = {'expr': expr, 'settings': settings}
            h = hashlib.md5(json.dumps(cache_payload, sort_keys=True).encode('utf-8')).hexdigest()
            
            if h in self.client.history:
                cached_data = self.client.history[h]
                if isinstance(cached_data, dict):
                    results[expr] = cached_data
                else:
                    # å…¼å®¹æ—§ç‰ˆæœ¬
                    results[expr] = {'score': cached_data, 'url': 'Legacy Cache Hit'}
            else:
                to_run.append(expr)

        if not to_run: return results

        logging.info(f"å¹¶å‘æäº¤ {len(to_run)} ä¸ªæ¨¡æ‹Ÿ (è®¾ç½®: {settings.get('neutralization', 'NONE')}/{settings.get('decay', 0)})...")
        futures = {}
        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT) as executor:
            for expr in to_run:
                # å¢åŠ å»¶è¿Ÿï¼Œé˜²æ­¢æäº¤å¤ªå¿«è§¦å‘ 429
                time.sleep(random.uniform(1.1, 2.1))
                sim_data = {'type': 'REGULAR', 'settings': settings, 'regular': expr}
                futures[executor.submit(self.client.submit_simulation, sim_data)] = expr

        loc_map = {}
        for f in as_completed(futures):
            expr = futures[f]
            try:
                loc = f.result()
                if loc:
                    loc_map[loc] = expr
                    logging.info(f"  -> å·²æäº¤: {loc}")
                    logging.info(f"     [å…¬å¼]: {expr}")
                else:
                    results[expr] = {'score': 0, 'url': 'Submission Failed'}
            except Exception as e:
                logging.warning(f"æäº¤å¼‚å¸¸: {e}")

        wait_futures = {}
        completed_count = 0
        total_tasks = len(loc_map)

        with ThreadPoolExecutor(max_workers=MAX_CONCURRENT) as executor:
            for loc, expr in loc_map.items():
                wait_futures[executor.submit(self.client.wait_for_simulation, loc)] = (expr, loc)

        for f in as_completed(wait_futures):
            expr, loc = wait_futures[f]
            try:
                res = f.result()
                # å¦‚æœç»“æœä¸ºç©ºï¼Œå°è¯•æœ€åä¸€æ¬¡æŠ¢æ•‘æ€§æŸ¥è¯¢
                if not res:
                    logging.warning(f"  âš ï¸ [ç»“æœä¸¢å¤±] {loc} è¿”å› Noneï¼Œå°è¯•æœ€åä¸€æ¬¡æŸ¥è¯¢...")
                    time.sleep(2)
                    res = self.client.wait_for_simulation(loc)

                # å°†ç»“æœå­˜å…¥å­—å…¸ï¼Œå¹¶ç”± _process_result å†…éƒ¨å¤„ç†åè½¬
                self._process_result(res, expr, loc, results, settings)

                completed_count += 1
                logging.info(f"   [è¿›åº¦] {completed_count}/{total_tasks} æ‰¹æ¬¡ä»»åŠ¡å·²å®Œæˆ")
            except Exception as e:
                logging.warning(f"è·å–ç»“æœå¼‚å¸¸: {e}")

        return results

    def _process_result(self, res, expr, location, results_dict=None, settings=None):
        """å¤„ç†å•ä¸ªç»“æœ"""
        current_settings = settings if settings is not None else self.settings
        
        # --- è¡¥æ•‘é€»è¾‘åŠ å¼ºï¼šå¦‚æœ res åªæ˜¯ä¸ª simulation å¯¹è±¡æˆ–æŠ¥è¡¨ç¼ºå¤±ï¼Œé€šè¿‡ ID å¼ºåˆ¶å–å› ---
        if res and ('is' not in res or res['is'].get('sharpe') is None):
            aid = res.get('alpha') or res.get('id')
            if aid and len(aid) > 5: # ç®€å•çš„ ID åˆæ³•æ€§æ£€æŸ¥
                logging.info(f"   ğŸ” [å¼ºåŠ›å–å›] æŠ¥è¡¨ç¼ºå¤±æˆ–ä¸å®Œæ•´ï¼Œé€šè¿‡ Alpha ID {aid} ç›´æ¥æŸ¥è¯¢è¯¦æƒ…...")
                # å¾ªç¯é‡è¯•å‡ æ¬¡ï¼Œå› ä¸ºå¹³å°ç”ŸæˆæŠ¥è¡¨å¯èƒ½éœ€è¦ä¸€ç‚¹æ—¶é—´
                for attempt in range(5):
                    details = self.client.get_alpha_details(aid)
                    if details and 'is' in details and details['is'].get('sharpe') is not None:
                        res = details
                        logging.info(f"   âœ… [å–å›æˆåŠŸ] å·²æˆåŠŸæ‹¿å› Alpha {aid} çš„ç»Ÿè®¡æ•°æ®ã€‚")
                        break
                    time.sleep(2)
        # --------------------------------------------------------------------------

        score = 0
        stats_dict = {'sharpe': 0, 'fitness': 0, 'margin': 0}
        alpha_id = None

        if res and 'is' in res:
            alpha_id = res['id']  # è·å–Alpha ID
            is_stats = res['is']
            sharpe = is_stats.get('sharpe', 0)
            fitness = is_stats.get('fitness', 0)
            margin = is_stats.get('margin', 0)
            turnover = is_stats.get('turnover', 0)

            # æ£€æŸ¥æ˜¯å¦ä¸ºå‚å­—å‹Alpha
            if self.client.check_factory_shape(alpha_id):
                # å‚å­—å‹Alphaç›´æ¥ç»™0åˆ†å¹¶æ ‡è®°ä¸ºç´«è‰² (ä»…å½“æ— é¢œè‰²æ—¶)
                logging.info(f"  ğŸŸ£ æ£€æµ‹åˆ°å‚å­—å‹Alpha: {alpha_id}")
                if not res.get('color'):
                    self.client.set_alpha_color(alpha_id, 'PURPLE')
                    logging.info(f"  -> å·²å°†å…¶æ ‡è®°ä¸ºç´«è‰²")
                else:
                    logging.info(f"  -> è¯¥Alphaå·²æœ‰é¢œè‰² '{res.get('color')}'ï¼Œè·³è¿‡å˜è‰²")

                # æ›´æ–°ç»“æœå­—å…¸ï¼ˆå‚å­—å‹è®°0åˆ†ï¼‰
                if results_dict is not None:
                    results_dict[expr] = {
                        'score': 0,
                        'url': location,
                        'stats': {'sharpe': 0, 'fitness': 0, 'margin': 0, 'passed': False, 'factory_shape': True},
                        'alpha_id': alpha_id
                    }
                return 0

            # å¤„ç† None å€¼ï¼Œå°†å…¶è½¬æ¢ä¸º 0
            if sharpe is None:
                sharpe = 0.0
            if fitness is None:
                fitness = 0.0
            if margin is None:
                margin = 0.0
                logging.warning(f"  -> Margin ä¸º Noneï¼Œå·²æ›¿æ¢ä¸º 0.0")

            # æ–°å¢æ¡ä»¶ï¼šå¦‚æœmarginå¤§äºä¸‡åˆ†ä¹‹100(0.01)ï¼Œåˆ™marginæŒ‰0è®¡ç®—
            if margin > 0.01:
                logging.info(f"  -> Margin ({margin:.4f}) å¤§äº100â€±ï¼Œmarginåˆ†æ•°æŒ‰0è®¡ç®—")
                margin_score = 0.0
            else:
                margin_score = margin

            is_passed = False
            if 'checks' in is_stats:
                checks = is_stats['checks']
                if checks and not any(c.get('result') == 'FAIL' for c in checks):
                    is_passed = True

            pass_bonus = PASS_BONUS if is_passed else 0.0

            # å‚å­—å‹æ£€æŸ¥ä»…ç”¨äºæ ‡è®°ï¼Œä¸å½±å“è¯„åˆ†
            is_factory_ok = True

            # å¤„ç† None å€¼ï¼Œå°†å…¶è½¬æ¢ä¸º 0
            if sharpe is None:
                sharpe = 0.0
            if fitness is None:
                fitness = 0.0
            if margin is None:
                margin = 0.0

            # --- [ç›¸å…³æ€§æ ¡å‡†ä¸å®šè‰²] ---
            sc_val = None
            pc_val_from_name = None
            is_newly_colored = False
            
            if is_passed:
                try:
                    # 1. å…ˆæŸ¥å®˜æ–¹çŠ¶æ€
                    details = self.client.get_alpha_details(alpha_id)
                    current_color = details.get('color', '')
                    current_name = details.get('name', '')
                    
                    if current_color:
                        logging.info(f"   [å…¼å®¹æ¨¡å¼] Alpha {alpha_id} å·²æœ‰é¢œè‰² '{current_color}'ï¼Œè§£æåå­—è¡¥å…¨æ•°æ®...")
                        pc_parsed, sc_parsed = self._extract_scores_from_name(current_name)
                        sc_val = sc_parsed
                        pc_val_from_name = pc_parsed

                    # å¦‚æœåå­—é‡Œæ²¡ SCï¼Œæˆ–è€…æ ¹æœ¬æ²¡é¢œè‰²ï¼Œåˆ™æœ¬åœ°è®¡ç®—
                    if sc_val is None:
                        logging.info(f"   [æœ¬åœ°SCæ£€æŸ¥] Alpha {alpha_id} æ­£åœ¨è®¡ç®— SC...")
                        sc_val = self.client.calculate_sc_locally(alpha_id, self.os_pool)
                        
                        if not current_color:
                            formatted_sc = sc_val if sc_val is not None else 0.0
                            new_name = f"SC{formatted_sc:.4f}"
                            self.client.set_alpha_name(alpha_id, new_name)
                            
                            final_color = 'GREEN'
                            if sc_val is not None and sc_val > SC_CUTOFF: final_color = 'BLUE'
                            elif margin < MARGIN_THRESHOLD: final_color = 'BLUE'
                            
                            self.client.set_alpha_color(alpha_id, final_color)
                            is_newly_colored = True
                            logging.info(f"   ğŸ¨ [å®šè‰²/æ”¹å] Alpha {alpha_id} -> {new_name} | é¢œè‰²: {final_color}")
                except Exception as e:
                    logging.warning(f"SCå¤„ç†å¤±è´¥: {e}")

            # --- [æœ€ç»ˆè¯„åˆ†ç³»ç»Ÿ] ---
            # 1. åŸºç¡€åˆ†: å¤æ™® + æ‹Ÿåˆåº¦
            # 2. æ¢æ‰‹ç‡å¼•å¯¼æƒ©ç½š: ä» 10% å¼€å§‹èµ·æ‰£ï¼Œ5å€ç³»æ•°
            to_penalty = max(0, turnover - 0.10) * 5.0

            # 3. Margin å¥–åŠ±: 50å€ç³»æ•°
            margin_reward = 50 * margin_score
            
            # 4. SC æƒ©ç½š (ç°åœ¨ sc_val å·²è·å–)
            sc_penalty = 0.0
            if sc_val is not None:
                sc_penalty = self.calculate_sc_penalty(sc_val)

            # 5. ç»¼åˆè®¡ç®— (åŸºç¡€åˆ† - TOæƒ©ç½š - SCæƒ©ç½š + Marginå¥–åŠ±)
            base_score = (sharpe + fitness) + margin_reward - to_penalty - abs(sc_penalty)
            final_score = max(0.0, base_score + pass_bonus)

            # æ‰“å°è¯¦ç»†æ‰£åˆ†æƒ…å†µ (ä»…å½“æœ‰æƒ©ç½šæ—¶)
            if to_penalty > 0 or abs(sc_penalty) > 0:
                logging.info(f"   [è¯„åˆ†è¯¦æƒ…] TOæƒ©ç½š: -{to_penalty:.4f} | SCæƒ©ç½š: {sc_penalty:.4f} | Marginå¥–åŠ±: +{margin_reward:.4f}")

            score = final_score
            # å°†è§£æå‡ºçš„æ•°æ®ä¹Ÿæ”¾å…¥ stats
            stats_dict = {
                'sharpe': sharpe, 'fitness': fitness, 'margin': margin, 
                'passed': is_passed, 'sc': sc_val, 'pc': pc_val_from_name,
                'is_newly_colored': is_newly_colored
            }

            # å°†ç»“æœå­˜å…¥ç»“æœå­—å…¸
            if results_dict is not None:
                results_dict[expr] = {
                    'score': score,
                    'url': location,
                    'stats': stats_dict,
                    'alpha_id': alpha_id
                }

            # ä¼˜åŒ–ç»ˆç«¯æ˜¾ç¤º
            status_icon = "âšª"
            color_code = "\033[90m" # é»˜è®¤ç°è‰²
            if is_passed:
                if (sc_val is not None and sc_val > SC_CUTOFF) or margin < MARGIN_THRESHOLD:
                    status_icon = "ğŸ”µ"
                    color_code = "\033[94m" # è“è‰²
                else:
                    status_icon = "ğŸŸ¢"
                    color_code = "\033[92m" # ç»¿è‰²
            
            logging.info(f"{color_code}--------------------------------------------------")
            logging.info(f"{status_icon} Alpha ID: {alpha_id} | Score: {final_score:.4f}")
            logging.info(f"   Sharpe: {sharpe:.2f} | Fitness: {fitness:.2f} | Margin: {margin:.4f} | TO: {turnover:.2%}")

            if hasattr(self, 'best_base_score'):
                if final_score - self.best_base_score > 1e-4:
                    logging.info(f"   \033[95m\033[1mğŸ‰ åŸºç¡€åˆ†å‘ç°æå‡! (+{final_score - self.best_base_score:.4f})\033[0m")
                elif abs(final_score - self.best_base_score) <= 1e-4:
                    logging.info(f"   åŸºç¡€åˆ†æŒå¹³")
            logging.info(f"{color_code}--------------------------------------------------\033[0m")

            # å¦‚æœ Sharpe å°äº -1.2ï¼Œå°±å–åå†æµ‹ä¸€æ¬¡ (å¢åŠ é˜²æ­»å¾ªç¯æ£€æŸ¥)
            if sharpe < -1.2:
                # æ£€æŸ¥æ˜¯å¦å·²ç»å–åè¿‡ï¼Œé˜²æ­¢æ— é™åµŒå¥— -1 * (-1 * ...)
                if expr.startswith("-1 * (") and expr.endswith(")"):
                    logging.info(f"   [å–åè·³è¿‡] å…¬å¼å·²å¤„äºå–åçŠ¶æ€ä¸” Sharpe ä¾ç„¶ä¸ºè´Ÿ ({sharpe:.2f})ï¼Œåœæ­¢é€’å½’å–åã€‚")
                else:
                    rev_expr = f"-1 * ({expr})"
                    # æ£€æŸ¥å–ååçš„å…¬å¼æ˜¯å¦å·²ç»åœ¨å†å²è®°å½•ä¸­ï¼ˆé¿å…é‡å¤å›æµ‹ï¼‰
                    # æ³¨æ„ï¼šåè½¬å…¬å¼çš„ç¼“å­˜é”®ä¹Ÿéœ€è¦åŒ…å« settings
                    rev_cache_payload = {'expr': rev_expr, 'settings': current_settings}
                    rev_h = hashlib.md5(json.dumps(rev_cache_payload, sort_keys=True).encode('utf-8')).hexdigest()
                    
                    if rev_h in self.client.history:
                        logging.info(f"   [å–åè·³è¿‡] åè½¬å…¬å¼å·²åœ¨å†å²ç¼“å­˜ä¸­: {rev_expr}")
                    else:
                        logging.info(f"[åè½¬] Sharpe ({sharpe:.2f}) < -1.2ï¼Œæ­£åŒæ­¥å›æµ‹å–åè¡¨è¾¾å¼: {rev_expr}")
                        rev_sim_data = {'type': 'REGULAR', 'settings': current_settings, 'regular': rev_expr}
                        try:
                            rev_loc = self.client.submit_simulation(rev_sim_data)
                            if rev_loc:
                                # åŒæ­¥ç­‰å¾…åè½¬ç»“æœ
                                rev_res = self.client.wait_for_simulation(rev_loc)
                                # é€’å½’è°ƒç”¨å¤„ç†åè½¬ç»“æœå¹¶å¡«å…¥å­—å…¸
                                self._process_result(rev_res, rev_expr, rev_loc, results_dict, current_settings)
                            else:
                                logging.warning(f"  [åè½¬å¤±è´¥] æ— æ³•æäº¤åè½¬è¡¨è¾¾å¼")
                        except Exception as e:
                            logging.warning(f"  [åè½¬å¼‚å¸¸] åè½¬å¤„ç†å¼‚å¸¸: {e}")
        else:
            logging.warning(f"  [å¼‚å¸¸] æ— æ³•è·å–ç»“æœæˆ–ç»Ÿè®¡æ•°æ®!")
            logging.warning(f"  URL: {location}")
            logging.warning(f"  Response: {res}")
            logging.warning("-" * 20)

            # æ— æ³•è·å–ç»“æœçš„Alphaåˆ†æ•°è®¾ä¸º0ï¼Œä¸å‚ä¸æ¯”è¾ƒ
            score = 0.0
            stats_dict = {'sharpe': 0, 'fitness': 0, 'margin': 0, 'passed': False}

        # ä¿å­˜åˆ°å†å²è®°å½• (æ ¸å¿ƒä¿®å¤ï¼šç¼“å­˜é”®åº”åŒ…å« settingsï¼Œå€¼åŒ…å«å®Œæ•´ä¿¡æ¯)
        cache_payload = {'expr': expr, 'settings': current_settings}
        h = hashlib.md5(json.dumps(cache_payload, sort_keys=True).encode('utf-8')).hexdigest()
        
        # å­˜å…¥å®Œæ•´ç»“æœåŒ…
        self.client.history[h] = {
            'score': score,
            'url': location,
            'stats': stats_dict,
            'alpha_id': alpha_id
        }

        return score
    def optimize_single_alpha(self, alpha_id):
        """ä¼˜åŒ–å•ä¸ªAlpha - å¼‚æ­¥ç‰ˆæœ¬"""
        logging.info(f"å¼€å§‹å¼‚æ­¥ä¼˜åŒ– Alpha ID: {alpha_id}")

        # ä¸ºæ¯ä¸ªAlpha IDä½¿ç”¨å•ç‹¬çš„æ£€æŸ¥ç‚¹æ–‡ä»¶
        if not self.load_checkpoint(alpha_id):
            logging.info(f"åˆå§‹åŒ–ç›®æ ‡ Alpha: {alpha_id}")
            details = self.client.get_alpha_details(alpha_id)
            if not details:
                logging.error(f"æ— æ³•è·å– Alpha {alpha_id} çš„è¯¦æƒ…")
                return

            self.settings = details['settings']
            regular = details['regular']
            self.best_expr = regular if isinstance(regular, str) else regular['code']
            self.best_alpha_id = alpha_id  # è®¾ç½®åˆå§‹Alpha ID
            self.initial_alpha_id = alpha_id  # è®¾ç½®åˆå§‹Alpha ID

            # ä¼˜å…ˆä½¿ç”¨ç°æœ‰ç»Ÿè®¡æ•°æ®
            is_stats = details.get('is', {})
            if 'sharpe' in is_stats and 'fitness' in is_stats:
                logging.info("ç›´æ¥ä» Alpha è¯¦æƒ…è·å–ç°æœ‰åˆ†æ•°...")

                # æ£€æŸ¥æ˜¯å¦ä¸ºå‚å­—å‹Alpha
                is_factory_shape = self.client.check_factory_shape(alpha_id)
                if is_factory_shape:
                    # å‚å­—å‹Alphaç›´æ¥ç»™0åˆ†å¹¶æ ‡è®°ä¸ºç´«è‰² (ä»…å½“æ— é¢œè‰²æ—¶)
                    logging.info(f"  ğŸŸ£ æ£€æµ‹åˆ°åˆå§‹å‚å­—å‹Alpha: {alpha_id}")
                    if not details.get('color'):
                        self.client.set_alpha_color(alpha_id, 'PURPLE')
                        logging.info(f"  -> å·²å°†å…¶æ ‡è®°ä¸ºç´«è‰²")
                    else:
                        logging.info(f"  -> è¯¥Alphaå·²æœ‰é¢œè‰² '{details.get('color')}'ï¼Œè·³è¿‡å˜è‰²")

                    with self.score_lock:
                        self.best_score = 0
                        self.initial_score = 0

                # æ£€æŸ¥å®˜æ–¹ PASS çŠ¶æ€
                is_passed = False
                if 'checks' in is_stats:
                    checks = is_stats['checks']
                    if checks and not any(c.get('result') == 'FAIL' for c in checks):
                        is_passed = True

                # å¦‚æœé€šè¿‡äº†æ‰€æœ‰æ£€æŸ¥ï¼Œåˆ™å°†Alphaæ ‡è®°ä¸ºç»¿è‰² (ä»…å½“æ— é¢œè‰²æ—¶)
                if is_passed:
                    try:
                        if not details.get('color'):
                            self.client.set_alpha_color(alpha_id, 'GREEN')
                            logging.info(f"  ğŸŸ¢ åˆå§‹Alpha ID: {alpha_id} å·²é€šè¿‡æ‰€æœ‰æ£€æŸ¥ï¼Œå·²æ ‡è®°ä¸ºç»¿è‰²")
                        else:
                            logging.info(f"  ğŸŸ¢ åˆå§‹Alpha ID: {alpha_id} å·²é€šè¿‡æ‰€æœ‰æ£€æŸ¥ï¼Œä½†å·²æœ‰é¢œè‰² '{details.get('color')}'ï¼Œè·³è¿‡å˜è‰²")
                    except Exception as e:
                        logging.warning(f"è®¾ç½®Alphaé¢œè‰²å¤±è´¥: {e}")

                pass_score = PASS_BONUS if is_passed else 0.0
                sharpe = is_stats.get('sharpe', 0)
                fitness = is_stats.get('fitness', 0)
                margin = is_stats.get('margin', 0)
                # å¤„ç† None å€¼ï¼Œå°†å…¶è½¬æ¢ä¸º 0
                if sharpe is None:
                    sharpe = 0.0
                if fitness is None:
                    fitness = 0.0
                if margin is None:
                    margin = 0.0
                    logging.warning(f"  -> åˆå§‹ Alpha Margin ä¸º Noneï¼Œå·²æ›¿æ¢ä¸º 0.0")

                # æ–°å¢æ¡ä»¶ï¼šå¦‚æœmarginå¤§äºä¸‡åˆ†ä¹‹100(0.01)ï¼Œåˆ™marginæŒ‰0è®¡ç®—
                if margin > 0.01:
                    logging.info(f"  -> åˆå§‹ Alpha Margin ({margin:.4f}) å¤§äº100â€±ï¼Œmarginåˆ†æ•°æŒ‰0è®¡ç®—")
                    margin_score = 0.0
                else:
                    margin_score = margin

                # ä½¿ç”¨å…¨æ–°çš„ [v4.7] æ ‡å‡†é‡ç®—åˆå§‹åˆ†
                turnover = details.get('is', {}).get('turnover', 0) or 0.0
                
                to_penalty = max(0, turnover - 0.10) * 5.0
                margin_reward = 50 * margin_score
                sc_penalty = 0.0 # åˆå§‹ Alpha æš‚æ—¶æ— æ³•è·å– SCï¼Œå…ˆè®¾ä¸º0

                base_score_only = (sharpe + fitness) + margin_reward - to_penalty - abs(sc_penalty)
                final_score = max(0.0, base_score_only + pass_score)

                with self.score_lock:
                    self.best_score = final_score
                    self.best_base_score = base_score_only
                    self.best_stats = {
                        'sharpe': sharpe,
                        'fitness': fitness,
                        'margin': margin,
                        'passed': is_passed,
                        'sc': None,
                        'pc': None
                    }
                    self.initial_score = self.best_score  # ä¿å­˜åˆå§‹åˆ†æ•°

                logging.info(f"ä¿¡ä»»åˆå§‹ Alpha åˆ†æ•°: {self.best_score:.4f} (Pass: {is_passed})")
                logging.info(f"  è¯¦ç»†è®¡ç®—è¿‡ç¨‹:")
                logging.info(f"    Sharpe: {sharpe:.4f} | Fitness: {fitness:.4f}")
                logging.info(f"    Marginå¥–åŠ±: +{margin_reward:.4f} | TOæƒ©ç½š: -{to_penalty:.4f}")
                logging.info(f"    Pass Bonus: {pass_score:.4f} | æœ€ç»ˆå¾—åˆ†: {final_score:.4f}")

                # --- v4.7 åˆå§‹ Alpha ç›¸å…³æ€§æ£€æŸ¥ä¸æ ‡è®° (ç§’å¼€/å¼‚æ­¥æ ¡å‡†ç‰ˆ) ---
                if sharpe != 0:
                    logging.info(f"   [åŸºå‡†å¼ºåˆ¶æ ¡å‡†] æ­£åœ¨åˆ·æ–°åˆå§‹ Alpha {alpha_id} çš„æ ¡å‡†æ•°æ®...")
                    
                    # 1. å°è¯•ä»åå­—ç›´æ¥è§£æ (ç§’å¼€é€»è¾‘)
                    current_name = details.get('name', '')
                    pc_parsed, sc_parsed = self._extract_scores_from_name(current_name)
                    
                    # 2. å¦‚æœåå­—é‡Œæœ‰ï¼Œç›´æ¥ç”¨
                    if pc_parsed is not None:
                        logging.info(f"   âœ¨ å‘ç°å†å²æ ‡è®°: PC={pc_parsed:.4f}, SC={sc_parsed if sc_parsed else 'æœªçŸ¥'}")
                        self.best_pc = pc_parsed
                        sc_val = sc_parsed if sc_parsed is not None else self.calculate_sc_locally(alpha_id, self.os_pool)
                        
                        # è®¡ç®—å„é¡¹å¥–æƒ©
                        sc_penalty = self.calculate_sc_penalty(sc_val)
                        pc_bonus = (0.7 - self.best_pc) * 10
                        pass_val = PASS_BONUS if is_passed else 0.0
                        
                        with self.score_lock:
                            # æ˜¾å¼åŠ ä¸Šæ‰€æœ‰åˆ†é¡¹
                            self.best_score = self.best_base_score + sc_penalty + pc_bonus + pass_val
                            self.best_score = max(self.best_score, 0.0)
                            # å…³é”®ï¼šå¯¹é½èµ·ç‚¹ï¼Œè®©æå‡ä» 0 å¼€å§‹
                            self.initial_score = self.best_score
                            
                        logging.info(f"   [æ ¡å‡†è¯¦æƒ…] Base: {self.best_base_score:.4f} | Pass: {pass_val} | SCæƒ©ç½š: {sc_penalty:.4f} | PCå¥–åŠ±: {pc_bonus:.4f}")
                        logging.info(f"   âœ… åŸºå‡†åˆ†å·²æ ¡å‡† (èµ·ç‚¹å·²å¯¹é½): {self.best_score:.4f}")
                    else:
                        # 3. åå­—é‡Œæ²¡æœ‰ï¼Œèµ°å¼‚æ­¥åå°æ£€æµ‹ (ä¸å¡é¡¿é€»è¾‘)
                        logging.info(f"   ğŸ“¡ åå­—ä¸­æ—  PC ä¿¡æ¯ï¼Œå¯åŠ¨åå°çº¿ç¨‹å¼‚æ­¥è·å–ï¼Œå…ˆä»¥åŸºç¡€åˆ†å¼€å§‹çˆ¬å±±...")
                        
                        # å…ˆè®¡ç®—æœ¬åœ° SC åšåˆæ­¥ä¿®æ­£
                        sc_val = self.calculate_sc_locally(alpha_id, self.os_pool)
                        sc_penalty = self.calculate_sc_penalty(sc_val) # ä½¿ç”¨æ–°é€»è¾‘è®¡ç®—æƒ©ç½š
                        
                        logging.info(f"   [æœ¬åœ°SCé¢„ä¼°] SC={sc_val} -> æƒ©ç½š={sc_penalty:.4f}")
                        
                        with self.score_lock:
                            self.best_pc = 0.7 # ä¸´æ—¶å ä½
                            self.best_score += sc_penalty
                        
                        # å¯åŠ¨åå°çº¿ç¨‹ (å®šä¹‰åœ¨ä¸‹æ–¹)
                        def bg_calibrate(aid, base_sc_penalty, passed_alpha):
                            logging.info(f"   [åå°æ ¡å‡†] å¼€å§‹å¼ºåŠ›è·å– {aid} çš„ PC...")
                            pc_v = self.client.get_product_correlation(aid, max_attempts=40)
                            if pc_v is not None:
                                pc_b = (0.7 - pc_v) * 10
                                with self.score_lock:
                                    if self.best_alpha_id == aid:
                                        old_s = self.best_score
                                        self.best_pc = pc_v
                                        # ä¿®å¤ï¼šæ ¡å‡†æ—¶å¿…é¡»åŠ ä¸Š PASS_BONUS
                                        self.best_score = self.best_base_score + base_sc_penalty + pc_b + (PASS_BONUS if passed_alpha else 0)
                                        self.best_score = max(self.best_score, 0.0)
                                        # å…³é”®ï¼šå¯¹é½èµ·ç‚¹
                                        self.initial_score = self.best_score
                                        logging.info(f"   [åå°æ ¡å‡†å®Œæˆ] âš–ï¸ ä¿®æ­£åˆå§‹æœ€ä¼˜æ€»åˆ† (èµ·ç‚¹å·²å¯¹é½): {old_s:.4f} -> {self.best_score:.4f} (PC: {pc_v:.4f})")
                                        self.save_checkpoint(aid)
                                # è¡¥å…¨æ”¹å
                                sc_v = self.calculate_sc_locally(aid, self.os_pool)
                                new_n = f"PC{pc_v:.4f}-SC{sc_v:.4f}"
                                self.client.set_alpha_name(aid, new_n)
                                if pc_v >= 0.7: self.client.set_alpha_color(aid, 'BLUE')
                        
                        t = threading.Thread(target=bg_calibrate, args=(alpha_id, sc_penalty, is_passed))
                        t.daemon = True
                        t.start()
                # ---------------------------------------
            else:
                logging.info("æœªæ‰¾åˆ°ç°æœ‰ç»Ÿè®¡æ•°æ®ï¼Œè¿›è¡Œåˆå§‹å›æµ‹...")
                results = self.evaluate_batch([self.best_expr])
                if results and self.best_expr in results:
                    initial_data = results[self.best_expr]
                    with self.score_lock:
                        self.best_score = initial_data['score']
                        self.best_base_score = initial_data['score']
                        self.best_alpha_id = initial_data.get('alpha_id')
                        self.best_stats = initial_data.get('stats', {})
                        self.initial_score = self.best_score
                    logging.info(f"åˆå§‹å›æµ‹å®Œæˆ: Score={self.best_score}, Alpha ID={self.best_alpha_id}")
                else:
                    with self.score_lock:
                        self.best_score = -9999
                        self.initial_score = -9999

            self.save_checkpoint(alpha_id)

        logging.info("=" * 50)
        logging.info(f"åˆå§‹å…¬å¼: {self.best_expr}")
        logging.info(f"åˆå§‹åˆ†æ•°: \033[97m{self.initial_score:.4f}\033[0m (ID: {self.initial_alpha_id})")
        logging.info(f"å½“å‰æœ€ä¼˜åˆ†æ•°: \033[97m{self.best_score:.4f}\033[0m (ID: {self.best_alpha_id})")
        logging.info("=" * 50)

        parser = SmartExpression(self.best_expr, self.settings, self.client)

        # 1. ä¼˜åŒ–æ•°æ®å­—æ®µ (Data Field)
        n_data = len([t for t in parser.tokens if t['type'] == 'data_field'])
        if self.current_position['data_field'] < n_data:
            logging.info(f">>> å¼€å§‹ä¼˜åŒ–æ•°æ®å­—æ®µ (å…± {n_data} ä¸ªä½ç½®)")
            for i in range(self.current_position['data_field'], n_data):
                if self.stop_requested: 
                    logging.info("ğŸ›‘ [å¤–å±‚ä¸­æ–­] åœæ­¢ä¼˜åŒ–æ•°æ®å­—æ®µ")
                    break
                self._optimize_step(parser, 'data_field', i, alpha_id)
                self.current_position['data_field'] = i + 1
                self.save_checkpoint(alpha_id)
        
        # 2. ä¼˜åŒ–æ•°å€¼ (Number/TimeWindow - å›å½’ v4.4 ç¨³å¥é¡ºåº)
        parser = SmartExpression(self.best_expr, self.settings, self.client)
        # æ‰¾åˆ°æ‰€æœ‰é lambda/tvr å‚æ•°çš„æ•°å­— Token
        n_nums = len([t for t in parser.tokens if t['type'] == 'number' 
                     and not t['text'].startswith('lambda_') 
                     and 'tvr' not in t['text']])
        
        if self.current_position['number'] < n_nums:
            logging.info(f">>> å¼€å§‹æŒ‰é¡ºåºä¼˜åŒ–æ‰€æœ‰æ•°å€¼ä½ç½® (å…± {n_nums} ä¸ª)")
            for i in range(self.current_position['number'], n_nums):
                if self.stop_requested: 
                    logging.info("ğŸ›‘ [å¤–å±‚ä¸­æ–­] åœæ­¢ä¼˜åŒ–æ•°å€¼ä½ç½®")
                    break
                # æ³¨æ„ï¼šç»Ÿä¸€ä½¿ç”¨ 'number' ç±»å‹è°ƒç”¨æ­¥è¿›ä¼˜åŒ–ï¼Œgenerate_neighbors å†…éƒ¨ä¼šè‡ªé€‚åº”å¤„ç†
                self._optimize_step(parser, 'number', i, alpha_id)
                self.current_position['number'] = i + 1
                self.save_checkpoint(alpha_id)

        # 4. ä¼˜åŒ–åˆ†ç»„ (Group)
        parser = SmartExpression(self.best_expr, self.settings, self.client)
        n_groups = len([t for t in parser.tokens if t['type'] == 'group'])
        if self.current_position['group'] < n_groups:
            logging.info(f">>> å¼€å§‹ä¼˜åŒ–åˆ†ç»„ (å…± {n_groups} ä¸ªä½ç½®)")
            for i in range(self.current_position['group'], n_groups):
                if self.stop_requested: 
                    logging.info("ğŸ›‘ [å¤–å±‚ä¸­æ–­] åœæ­¢ä¼˜åŒ–åˆ†ç»„")
                    break
                self._optimize_step(parser, 'group', i, alpha_id)
                self.current_position['group'] = i + 1
                self.save_checkpoint(alpha_id)

        # 5. ä¼˜åŒ–è¿ç®—ç¬¦ (Operator)
        parser = SmartExpression(self.best_expr, self.settings, self.client)
        n_ops = len([t for t in parser.tokens if t['type'] == 'operator'])
        if self.current_position['operator'] < n_ops:
            logging.info(f">>> å¼€å§‹ä¼˜åŒ–è¿ç®—ç¬¦ (å…± {n_ops} ä¸ªä½ç½®)")
            for i in range(self.current_position['operator'], n_ops):
                if self.stop_requested: 
                    logging.info("ğŸ›‘ [å¤–å±‚ä¸­æ–­] åœæ­¢ä¼˜åŒ–è¿ç®—ç¬¦")
                    break
                self._optimize_step(parser, 'operator', i, alpha_id)
                self.current_position['operator'] = i + 1
                self.save_checkpoint(alpha_id)

        # ä¼˜åŒ– neutralization å‚æ•°
        if not self.stop_requested:
            logging.info(f">>> å¼€å§‹ä¼˜åŒ– neutralization å‚æ•°")
            logging.info(f"ä»ç¬¬ {self.current_position['neutralization'] + 1} ä¸ªä½ç½®å¼€å§‹")
            self._optimize_settings_param('neutralization', CANDIDATE_NEUTRALIZATIONS,
                                          self.current_position['neutralization'], alpha_id)

        # ä¼˜åŒ– decay å‚æ•°
        if not self.stop_requested:
            logging.info(f">>> å¼€å§‹ä¼˜åŒ– decay å‚æ•°")
            logging.info(f"ä»ç¬¬ {self.current_position['decay'] + 1} ä¸ªä½ç½®å¼€å§‹")
            self._optimize_settings_param('decay', CANDIDATE_DECAYS,
                                          self.current_position['decay'], alpha_id)

        logging.info(" ")
        logging.info("\033[93m" + "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• Alpha ä¼˜åŒ–æŠ¥å‘Š â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—" + "\033[0m")
        logging.info(f" ğŸ åˆå§‹ Alpha: {self.initial_alpha_id}  -->  Score: {self.initial_score:.4f}")
        logging.info(f" ğŸ† æœ€ç»ˆ Alpha: {self.best_alpha_id}  -->  Score: {self.best_score:.4f}")
        improvement = self.best_score - self.initial_score
        logging.info(f" ğŸ“ˆ åˆ†æ•°æå‡: \033[92m{improvement:+.4f}\033[0m")
        
        # æå–è¯¦ç»†ç»“æœ
        final_details = self.client.get_alpha_details(self.best_alpha_id)
        final_is_passed = False
        final_stats_str = "æœªçŸ¥"
        if final_details and 'is' in final_details:
            final_is_passed = not any(c.get('result') == 'FAIL' for c in final_details['is'].get('checks', []))
            st = final_details['is']
            final_stats_str = f"Sharpe: {st.get('sharpe', 0):.2f} | Fitness: {st.get('fitness', 0):.2f} | Margin: {st.get('margin', 0):.4f}"
        
        status_text = "\033[92mé€šè¿‡ (Pass) âœ…\033[0m" if final_is_passed else "\033[91mæœªé€šè¿‡ (Fail) âŒ\033[0m"
        logging.info(f" ğŸ›¡ï¸ æ£€æŸ¥ç»“æœ: {status_text}")
        logging.info(f" ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡: {final_stats_str}")
        logging.info(f" ğŸ“„ æœ€ç»ˆè¡¨è¾¾å¼: \033[97m{self.best_expr}\033[0m")
        logging.info("\033[93m" + "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•" + "\033[0m")
        logging.info(" ")

        # å‘é€å®Œæˆé€šçŸ¥é‚®ä»¶
        if EMAIL_CONFIG.get('enabled', False):
            # è·å–åˆå§‹Alphaå’Œæœ€ç»ˆAlphaçš„é€šè¿‡çŠ¶æ€
            initial_details = self.client.get_alpha_details(self.initial_alpha_id) if self.initial_alpha_id else None
            final_details = self.client.get_alpha_details(self.best_alpha_id) if self.best_alpha_id else None
            
            initial_passed = False
            final_passed = False
            
            if initial_details and 'is' in initial_details and 'checks' in initial_details['is']:
                checks = initial_details['is']['checks']
                if checks and not any(c.get('result') == 'FAIL' for c in checks):
                    initial_passed = True
                    
            if final_details and 'is' in final_details and 'checks' in final_details['is']:
                checks = final_details['is']['checks']
                if checks and not any(c.get('result') == 'FAIL' for c in checks):
                    final_passed = True
            
            subject = f"Alpha {alpha_id} å›æµ‹ä»»åŠ¡å·²å®Œæˆ"
            
            # æå–æœ€ç»ˆè¯¦ç»†ç»Ÿè®¡
            final_stats = "æœªçŸ¥"
            if final_details and 'is' in final_details:
                st = final_details['is']
                final_stats = f"Sharpe: {st.get('sharpe', 0):.2f}, Fitness: {st.get('fitness', 0):.2f}, Margin: {st.get('margin', 0):.4f}, TO: {st.get('turnover', 0):.2%}"

            content = f"""æ‚¨çš„ Alpha {alpha_id} å›æµ‹ä»»åŠ¡å·²ç»å…¨éƒ¨å®Œæˆï¼

ğŸ åˆå§‹ Alpha: {self.initial_alpha_id} | åˆ†æ•°: {self.initial_score:.4f}
ğŸ† æœ€ç»ˆ Alpha: {self.best_alpha_id} | åˆ†æ•°: {self.best_score:.4f}
ğŸ“ˆ æ€»è®¡æå‡: {improvement:+.4f}
âœ… æ˜¯å¦é€šè¿‡æ£€æŸ¥: {'é€šè¿‡ (Pass)' if final_is_passed else 'æœªé€šè¿‡ (Fail)'}
âœ¨ æœ€ç»ˆæŒ‡æ ‡: {final_stats}
ğŸ“„ æœ€ç»ˆè¡¨è¾¾å¼: {self.best_expr}

è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶: {os.path.join(OUTPUT_DIR, f"{alpha_id}_hill_climbing_v4.7.log")}
"""
            send_qq_email(subject, content)

    def _optimize_step(self, parser, type_name, index, alpha_id):
        """åŒæ­¥ä¼˜åŒ–å•ä¸ªæ­¥éª¤ (æ¢å¤ v4.3 é€»è¾‘)"""
        start_step_score = self.best_score

        if self.best_expr != parser.original_expr:
            parser = SmartExpression(self.best_expr, self.settings, self.client)

        neighbors = parser.generate_neighbors(type_name, index)
        if not neighbors: return

        logging.info(
            f"æ­£åœ¨ä¼˜åŒ– {type_name} ç¬¬ {index + 1} ä¸ªä½ç½®ï¼Œå…± {len(neighbors)} ä¸ªå€™é€‰é¡¹... (å½“å‰åŸºå‡†: {self.best_score:.4f})")

        # ä¼˜åŒ–ï¼šå¦‚æœå€™é€‰é¡¹è¾ƒå°‘ï¼Œç›´æ¥ä¸€æ¬¡æ€§å…¨å‘äº†ï¼Œä½†ä¸ºäº†é˜² 429ï¼Œä¸Šé™è®¾ä¸º 16
        # é’ˆå¯¹ number ç±»å‹ï¼Œç”±äºå€™é€‰æ± å›ºå®šä¸”é‡è¦ï¼Œå°è¯•ä¸€æ¬¡æ€§æµ‹å®Œ (ä¸Šé™æå‡è‡³ 64)
        current_batch_size = BATCH_SIZE
        if type_name == 'number':
            current_batch_size = min(len(neighbors), 64)
            logging.info(f"  > ç­–ç•¥ä¼˜åŒ–ï¼šé’ˆå¯¹ number å…¨é‡æäº¤ (Size: {current_batch_size})...")
        elif len(neighbors) <= 16 or type_name in ['time_window', 'neutralization']:
            current_batch_size = min(len(neighbors), 16)
            logging.info(f"  > ç­–ç•¥ä¼˜åŒ–ï¼šé’ˆå¯¹ {type_name} æˆ–å°æ ·æœ¬ï¼Œå°†æ‰¹é‡æäº¤æµ‹è¯• (Size: {current_batch_size})...")

        # ä»æ£€æŸ¥ç‚¹ä¸­å­˜å‚¨çš„æ‰¹æ¬¡åç§»é‡å¼€å§‹å¤„ç†
        start_batch = self.current_position.get('batch_offset', 0)

        for i in range(start_batch, len(neighbors), current_batch_size):
            batch = neighbors[i:i + current_batch_size]
            batch_index = i // current_batch_size + 1
            total_batches = (len(neighbors) - 1) // current_batch_size + 1
            logging.info(f"  > å¤„ç†æ‰¹æ¬¡ {batch_index}/{total_batches} (æœ¬æ‰¹ {len(batch)} ä¸ª)... [ä½ç½®: {type_name} ç¬¬ {index + 1} ä¸ª]")

            results = self.evaluate_batch(batch)

            if not results: continue

            # æ‰¾åˆ°æœ¬æ‰¹æ¬¡ä¸­çš„æœ€ä¼˜è§£ (ä¼˜å…ˆçº§: Passä¸”ä½SC > Passä¸”é«˜SC > Failï¼ŒåŒçº§æ¯”åˆ†)
            def sort_key(expr):
                data = results[expr]
                stats = data.get('stats', {})
                is_passed = stats.get('passed', False)
                sc_val = stats.get('sc')
                
                # å®šä¹‰å±‚çº§ (è¶Šå¤§è¶Šå¥½)
                if is_passed:
                    if sc_val is None or sc_val <= 0.7:
                        tier = 2  # ç¬¬ä¸€æ¢¯é˜Ÿ: çœŸæ­£ç»¿è‰²
                    else:
                        tier = 1  # ç¬¬äºŒæ¢¯é˜Ÿ: è“è‰² (Pass ä½†ç›¸å…³æ€§é«˜)
                else:
                    tier = 0      # ç¬¬ä¸‰æ¢¯é˜Ÿ: çº¢è‰² (Fail)
                
                # åˆ†æ•°å·²åŒ…å«SCæƒ©ç½šï¼Œç›´æ¥ä½¿ç”¨
                return (tier, data['score'])

            best_in_batch_expr = max(results, key=sort_key)
            best_in_batch_data = results[best_in_batch_expr]
            candidate_id = best_in_batch_data.get('alpha_id')
            # å®‰å…¨è·å– stats å­—å…¸
            res_stats = best_in_batch_data.get('stats', {})
            is_p = res_stats.get('passed', False)
            sc_val = res_stats.get('sc')
            pc_val = res_stats.get('pc') # æ¥æ”¶ä» _process_result é€ä¼ æ¥çš„è§£æå€¼

            # å‡†å…¥æœºåˆ¶å‡çº§ï¼šåªæœ‰æ²¡æœ‰ failã€åŸºç¡€åˆ†è¿›æ­¥ ä¸” SC åˆæ ¼ï¼Œæ‰æµ‹ PC
            if is_p and best_in_batch_data['score'] > self.best_base_score:
                sc_penalty = 0
                if sc_val is not None and sc_val > SC_CUTOFF:
                    logging.info(f"   [å‡†å…¥è·³è¿‡] SC ({sc_val:.4f}) > {SC_CUTOFF}ï¼Œä¸æµ‹ PCï¼Œç›´æ¥è¿›è¡Œä¸Šä½æŒ‘æˆ˜...")
                    sc_penalty = (SC_CUTOFF - sc_val) * 10
                    # å¦‚æœè¿™æ—¶å€™ pc_val ä¸ºç©ºï¼Œæˆ‘ä»¬ä¿æŒä¸ºç©º
                elif pc_val is None:
                    logging.info(f"   [å‡†å…¥é€šè¿‡] åŸºç¡€åˆ†çªç ´ä¸” SC åˆæ ¼ (<= {SC_CUTOFF})ï¼Œå¼€å§‹è·å– PC...")
                    pc_val = self.client.get_product_correlation(candidate_id)
                else:
                    logging.info(f"   [å‡†å…¥é€šè¿‡] åŸºç¡€åˆ†çªç ´ä¸” SC åˆæ ¼ï¼Œå·²ä»åå­—è§£æåˆ° PC={pc_val}")
                
                # è®¡ç®—æœ€ç»ˆè¯„ä¼°æ€»åˆ†
                if pc_val is not None:
                    # å†æ¬¡æ ¸å®å®˜æ–¹çŠ¶æ€ (ä¿æŠ¤å†å²æ ‡è®°)
                    details = self.client.get_alpha_details(candidate_id)
                    current_color = details.get('color', '')
                    is_new_color = res_stats.get('is_newly_colored', False)
                    
                    # åªæœ‰åœ¨æœ¬è½®æ–°ä¸Šçš„è‰²ï¼Œæˆ–è€…æ˜¯æ— è‰²çš„æƒ…å†µä¸‹ï¼Œæ‰å…è®¸å›å†™æ”¹å
                    if is_new_color or not current_color:
                        sc_val_val = sc_val if sc_val is not None else 0.0
                        new_name = f"PC{pc_val:.4f}-SC{sc_val_val:.4f}"
                        self.client.set_alpha_name(candidate_id, new_name)
                        # è¡¥æŸ“è“è‰² (å¦‚æœ PC è¶…æ ‡)
                        if pc_val >= 0.7:
                            self.client.set_alpha_color(candidate_id, 'BLUE')
                            logging.info(f"   ğŸ¨ [PCæŸ“è‰²] Alpha {candidate_id} -> BLUE")
                        else:
                            logging.info(f"   ğŸ“ [PCå‘½å] Alpha {candidate_id} -> {new_name}")
                    else:
                        logging.info(f"   [å…¼å®¹ä¿æŠ¤] Alpha {candidate_id} ç»´æŒå†å²æ ‡è®°ï¼Œè·³è¿‡æ”¹åã€‚")
                    
                    pc_bonus = (0.7 - pc_val) * 10
                    new_total_score = best_in_batch_data['score'] + pc_bonus
                    logging.info(f"   [ç»¼åˆè¯„ä¼°] æ€»åˆ†: {new_total_score:.4f} (PC: {pc_val:.4f}, å¥–æƒ©: {pc_bonus:+.4f}) | å½“å‰æœ€ä¼˜: {self.best_score:.4f}")
                else:
                    # SC > 0.7 æˆ– PC è·å–å¤±è´¥çš„æƒ…å†µ
                    new_total_score = best_in_batch_data['score'] + sc_penalty
                    logging.info(f"   [SCæŒ‘æˆ˜è¯„ä¼°] æ€»åˆ†: {new_total_score:.4f} (SCæ‰£åˆ†: {sc_penalty:.4f}) | å½“å‰æœ€ä¼˜: {self.best_score:.4f}")

                # åªè¦æ€»åˆ†æ›´é«˜ï¼Œä¸”æœªç†”æ–­ï¼Œå°±ä¸Šä½
                with self.score_lock:
                    if new_total_score > self.best_score:
                        if new_total_score < -1000: # è§¦å‘ç†”æ–­
                            logging.info(f"   âŒ æ€»åˆ†è™½é«˜ä½†ç›¸å…³æ€§è¶…è¿‡ç†”æ–­é˜ˆå€¼ï¼Œæ‹’ç»ä¸Šä½ã€‚")
                        else:
                            diff = new_total_score - self.best_score
                            logging.info(f"  \033[95m\033[1mğŸ‰ å‘ç°æ›´ä¼˜ç»¼åˆè§£! æ€»åˆ†: {new_total_score:.4f} (â†‘ {diff:+.4f})\033[0m")
                            
                            self.best_score = new_total_score
                            self.best_base_score = best_in_batch_data['score']
                            self.best_expr = best_in_batch_expr
                            self.best_alpha_id = candidate_id # å¼ºåˆ¶æ›´æ–°æœ€ä½³ ID
                            self.best_pc = pc_val
                            self.best_stats = best_in_batch_data.get('stats', {})

                            self.save_checkpoint(alpha_id)
                            parser = SmartExpression(self.best_expr, self.settings, self.client)
                    else:
                        base_improvement = best_in_batch_data['score'] - self.best_base_score
                        logging.info(f"   âŒ [åˆ¤å®šç»“æœ] è™½ç„¶åŸºç¡€åˆ†æå‡äº† {base_improvement:+.4f}ï¼Œä½†å› ç›¸å…³æ€§å¥–æƒ©åæ€»åˆ† ({new_total_score:.4f}) æœªèƒ½è¶…è¿‡å½“å‰æœ€ä¼˜ ({self.best_score:.4f})ï¼Œä¸äºˆä¸Šä½ã€‚")
            elif not is_p and best_in_batch_data['score'] > (self.best_base_score + 1.0):
                # å¦‚æœæ˜¯ Fail çš„é¡¹ï¼Œä½† Sharpe æå…¶é«˜ï¼ˆæ¯”å½“å‰ base è¿˜è¦é«˜å‡º 1 åˆ†ä»¥ä¸Šï¼‰ï¼Œè™½ç„¶ä¸æµ‹ PC ä½†æˆ‘ä»¬è®°å½•ä¸€ä¸‹
                logging.info(f"   ğŸ¥± æœ€å¼ºé¡¹ Fail äº†ï¼Œè·³è¿‡ç›¸å…³æ€§æ£€æŸ¥ã€‚ (åŸºç¡€åˆ†: {best_in_batch_data['score']:.4f})")
            else:
                logging.info(f"   ğŸ¥± åŸºç¡€åˆ†æœªçªç ´æˆ–å·² Failï¼Œè·³è¿‡ç›¸å…³æ€§æ£€æŸ¥ã€‚")

            # æ›´æ–°è¿›åº¦
            self.current_position['batch_offset'] = i + len(batch)
            self.save_checkpoint(alpha_id)

            # ä¼˜é›…é€€å‡ºæ£€æŸ¥ç‚¹
            if self.stop_requested:
                logging.info("ğŸ›‘ ä¼˜é›…é€€å‡ºï¼šå½“å‰ Batch åŠæ”¶å°¾å·¥ä½œå·²å®Œæˆï¼Œè¿›åº¦å·²ä¿å­˜ã€‚")
                import sys
                sys.exit(0)

        # é‡ç½®æ‰¹æ¬¡åç§»é‡
        self.current_position['batch_offset'] = 0
        self.save_checkpoint(alpha_id)

        # é˜¶æ®µæ€§æ€»ç»“
        total_improvement = self.best_score - self.initial_score
        step_improvement = self.best_score - start_step_score
        
        # æ ¼å¼åŒ–æŒ‡æ ‡è¯¦æƒ…
        stats_msg = "æš‚æ— è¯¦ç»†æŒ‡æ ‡"
        pass_status = "æœªçŸ¥"
        display_pc = f"{self.best_pc:.4f}" if self.best_pc is not None else "å¾…è·å–/è·³è¿‡"
        if self.best_stats:
            s = self.best_stats
            pass_status = "é€šè¿‡ âœ…" if s.get('passed') else "å¤±è´¥ âŒ"
            sc_val = f"{s.get('sc'):.4f}" if isinstance(s.get('sc'), (int, float)) else s.get('sc', 'æœªè®¡ç®—')
            stats_msg = (f"Sharpe: {s.get('sharpe', 0):.2f} | Fitness: {s.get('fitness', 0):.2f} | "
                         f"Margin: {s.get('margin', 0):.4f} | SC: {sc_val} | PC: {display_pc}")

        logging.info(" ")
        logging.info(f"\033[95m" + "=" * 20 + f" [ä½ç½®ä¼˜åŒ–æ€»ç»“: {type_name} ç¬¬ {index + 1} ä¸ªä½ç½®] " + "=" * 20 + "\033[0m")
        logging.info(f"  ğŸš© åˆå§‹ Alpha ID: {self.initial_alpha_id}")
        logging.info(f"  ğŸ† å½“å‰æœ€ä¼˜ Alpha: {self.best_alpha_id}")
        logging.info(f"  ğŸ’° å½“å‰æ€»åˆ†: \033[97m{self.best_score:.4f}\033[0m (åŸºç¡€åˆ†: {self.best_base_score:.4f})")
        logging.info(f"  ğŸ“ˆ æœ¬æ¬¡ä½ç½®æå‡: \033[92m{step_improvement:+.4f}\033[0m")
        logging.info(f"  ğŸš€ ç´¯è®¡æ€»æå‡: \033[92m{total_improvement:+.4f}\033[0m")
        logging.info(f"  ğŸ›¡ï¸ æ£€æŸ¥çŠ¶æ€: {pass_status}")
        logging.info(f"  ğŸ“Š è¯¦ç»†æŒ‡æ ‡: {stats_msg}")
        logging.info(f"  ğŸ“ å½“å‰æœ€ä½³å…¬å¼: \033[90m{self.best_expr}\033[0m")
        logging.info(f"\033[95m" + "=" * 75 + "\033[0m")
        logging.info(" ")

    def _optimize_settings_param(self, param_name, candidate_values, start_index, alpha_id):
        """åŒæ­¥ä¼˜åŒ–è®¾ç½®å‚æ•° (æ¢å¤ v4.3 é€»è¾‘)"""
        start_step_score = self.best_score

        if not self.settings:
            logging.warning(f"æ— æ³•ä¼˜åŒ– {param_name} å‚æ•°ï¼šç¼ºå°‘è®¾ç½®ä¿¡æ¯")
            return

        # ä»æŒ‡å®šç´¢å¼•å¼€å§‹éå†å€™é€‰å€¼
        for i in range(start_index, len(candidate_values)):
            candidate_value = candidate_values[i]
            logging.info(
                f"æ­£åœ¨ä¼˜åŒ– {param_name} å‚æ•°ï¼Œæµ‹è¯•å€¼: {candidate_value} (å½“å‰åŸºå‡†æ€»åˆ†: \033[97m{self.best_score:.4f}\033[0m)")

            # åˆ›å»ºæ–°çš„è®¾ç½®å‰¯æœ¬
            new_settings = self.settings.copy()
            new_settings[param_name] = candidate_value

            # ç”¨å½“å‰æœ€ä¼˜è¡¨è¾¾å¼å’Œæ–°è®¾ç½®è¿›è¡Œå›æµ‹
            results = self.evaluate_batch([self.best_expr], new_settings)

            if results and self.best_expr in results:
                res_data = results[self.best_expr]
                new_score = res_data['score']
                new_alpha_id = res_data.get('alpha_id')
                
                # --- ä¿®å¤ï¼šå®šä¹‰ res_stats å˜é‡ ---
                res_stats = res_data.get('stats', {})
                is_p = res_stats.get('passed', False)
                # -------------------------------

                # åŒæ ·éµå¾ªæ€§èƒ½å‡†å…¥ï¼šåŸºç¡€åˆ†æœ‰è¿›æ­¥ä¸”æœª Fail ä¸” SC åˆæ ¼æ‰æµ‹ PC
                if is_p and new_score > self.best_base_score:
                    sc_val = res_stats.get('sc')
                    pc_val = res_stats.get('pc') # æ¥æ”¶é€ä¼ å€¼
                    sc_penalty = 0
                    
                    if sc_val is not None and sc_val > SC_CUTOFF:
                        logging.info(f"   [è®¾ç½®å‡†å…¥è·³è¿‡] SC ({sc_val:.4f}) > {SC_CUTOFF}ï¼Œä¸æµ‹ PCï¼Œç›´æ¥è¿›è¡Œä¸Šä½æŒ‘æˆ˜...")
                        sc_penalty = (SC_CUTOFF - sc_val) * 10
                    elif pc_val is None:
                        logging.info(f"   [è®¾ç½®å‡†å…¥é€šè¿‡] åŸºç¡€åˆ†çªç ´ä¸” SC åˆæ ¼ï¼ŒæŸ¥è¯¢ PC...")
                        pc_val = self.client.get_product_correlation(new_alpha_id)
                    else:
                        logging.info(f"   [è®¾ç½®å‡†å…¥é€šè¿‡] åŸºç¡€åˆ†çªç ´ä¸” SC åˆæ ¼ï¼Œè§£æåˆ° PC={pc_val}")

                    if pc_val is not None:
                        # è®¡ç®—ä¿®æ­£åˆ† (æ­¤æ—¶ sc_penalty ä¸º 0)
                        pc_bonus = (0.7 - pc_val) * 10
                        new_total_score = new_score + pc_bonus
                        
                        with self.score_lock:
                            logging.info(f"   [è®¾ç½®è¯„ä¼°] æ€»åˆ†: {new_total_score:.4f} (PC: {pc_val:.4f}) | å½“å‰æœ€ä¼˜: {self.best_score:.4f}")

                            if new_total_score > self.best_score:
                                if new_total_score < -1000:
                                    logging.info(f"   âŒ è®¾ç½®ä¼˜åŒ–åç†”æ–­ï¼Œæ‹’ç»ä¸Šä½ã€‚")
                                else:
                                    self.best_score = new_total_score
                                    self.best_base_score = new_score
                                    self.settings = new_settings
                                    self.best_alpha_id = new_alpha_id # å¼ºåˆ¶æ›´æ–°æœ€ä½³ ID
                                    self.best_pc = pc_val
                                    self.best_stats = res_stats

                                    # å…ˆæŸ¥é¢œè‰²
                                    details = self.client.get_alpha_details(new_alpha_id)
                                    current_color = details.get('color', '')
                                    is_new_color = res_stats.get('is_newly_colored', False)
                                    
                                    if is_new_color or not current_color:
                                        sc_val_val = sc_val if sc_val is not None else 0.0
                                        new_name = f"PC{pc_val:.4f}-SC{sc_val_val:.4f}"
                                        self.client.set_alpha_name(new_alpha_id, new_name)
                                        if pc_val >= 0.7 and current_color != 'BLUE':
                                            self.client.set_alpha_color(new_alpha_id, 'BLUE')
                                    else:
                                        logging.info(f"   [è®¾ç½®å…¼å®¹] Alpha {new_alpha_id} ç»´æŒå†å²æ ‡è®°ã€‚")
                                    
                                    logging.info(f"  ğŸ‰ å‘ç°æ›´ä¼˜è®¾ç½®! æ€»åˆ†: {self.best_score:.4f}")
                                    self.save_checkpoint(alpha_id)
                    else:
                        # å…œåº•ï¼šç”¨åŸºç¡€åˆ†æŒ‘æˆ˜æ€»åˆ† (é€‚ç”¨äº SC > 0.7 æˆ– PC æ— æ³•è·å–çš„æƒ…å†µ)
                        new_total_score = new_score + sc_penalty
                        
                        with self.score_lock:
                            logging.info(f"   [è®¾ç½®SCæŒ‘æˆ˜è¯„ä¼°] æ€»åˆ†: {new_total_score:.4f} (SCæ‰£åˆ†: {sc_penalty:.4f}) | å½“å‰æœ€ä¼˜: {self.best_score:.4f}")
                            
                            if new_total_score > self.best_score:
                                if new_total_score < -1000:
                                    logging.info(f"   âŒ è®¾ç½®SCæŒ‘æˆ˜ç†”æ–­ï¼Œæ‹’ç»ä¸Šä½ã€‚")
                                else:
                                    self.best_score = new_total_score
                                    self.best_base_score = new_score
                                    self.settings = new_settings
                                    self.best_alpha_id = new_alpha_id # å¼ºåˆ¶æ›´æ–°æœ€ä½³ ID
                                    self.best_pc = 0.7 # è®°å½•ä¸ºä¸­æ€§
                                    self.best_stats = res_stats
                                    
                                    logging.info(f"  ğŸ‰ (SCæŒ‘æˆ˜æˆåŠŸ) å‘ç°æ›´ä¼˜è®¾ç½®! æ€»åˆ†: {self.best_score:.4f}")
                                    self.save_checkpoint(alpha_id)
                elif new_score > self.best_score:
                    # å¦‚æœåŸºç¡€åˆ†ä¸å¸¦ PC éƒ½æ¯”å½“å‰å¸¦ PC çš„æ€»åˆ†é«˜ï¼Œç›´æ¥ä¸Šä½
                    with self.score_lock:
                        if new_score > self.best_score:
                            self.best_score = new_score
                            self.best_base_score = new_score
                            self.settings = new_settings
                            self.best_alpha_id = new_alpha_id # å¼ºåˆ¶æ›´æ–°æœ€ä½³ ID
                            self.best_stats = res_stats
                            logging.info(f"  ğŸ‰ å‘ç°æ›´ä¼˜çš„ (çº¯åŸºç¡€åˆ†ä¸Šä½)! Score: {self.best_score:.4f}")
                            self.save_checkpoint(alpha_id)
            
            # æ›´æ–°å½“å‰ä½ç½®å¹¶ä¿å­˜æ£€æŸ¥ç‚¹
            self.current_position[param_name] = i + 1
            self.save_checkpoint(alpha_id)

        # å®Œæˆæ‰€æœ‰å€™é€‰å€¼åï¼Œé‡ç½®ä½ç½®
        self.current_position[param_name] = 0
        self.save_checkpoint(alpha_id)

        # é˜¶æ®µæ€§æ€»ç»“
        total_improvement = self.best_score - self.initial_score
        step_improvement = self.best_score - start_step_score
        
        # æ ¼å¼åŒ–æŒ‡æ ‡è¯¦æƒ…
        stats_msg = "æš‚æ— è¯¦ç»†æŒ‡æ ‡"
        pass_status = "æœªçŸ¥"
        display_pc = f"{self.best_pc:.4f}" if self.best_pc is not None else "å¾…è·å–/è·³è¿‡"
        if self.best_stats:
            s = self.best_stats
            pass_status = "é€šè¿‡ âœ…" if s.get('passed') else "å¤±è´¥ âŒ"
            sc_val = f"{s.get('sc'):.4f}" if isinstance(s.get('sc'), (int, float)) else s.get('sc', 'æœªè®¡ç®—')
            stats_msg = (f"Sharpe: {s.get('sharpe', 0):.2f} | Fitness: {s.get('fitness', 0):.2f} | "
                         f"Margin: {s.get('margin', 0):.4f}\n     SC: {sc_val} | PC: {display_pc}")

        logging.info(" ")
        logging.info("\033[93m" + "â•”" + "â•" * 65 + "â•—" + "\033[0m")
        logging.info(f"\033[93mâ•‘ âš™ï¸ [è®¾ç½®ä¼˜åŒ–æ€»ç»“] å‚æ•°: {param_name}" + " " * (43 - len(param_name)) + "â•‘\033[0m")
        logging.info("\033[93m" + "â• " + "â•" * 65 + "â•£" + "\033[0m")
        logging.info(f" ğŸš© åˆå§‹ Alpha: {self.initial_alpha_id}  -->  ğŸ† å½“å‰æœ€ä¼˜: {self.best_alpha_id}")
        logging.info(f" ğŸ“ˆ é˜¶æ®µæå‡: \033[92m{step_improvement:+.4f}\033[0m | ğŸš€ ç´¯è®¡æå‡: \033[92m{total_improvement:+.4f}\033[0m")
        logging.info(f" ğŸ’° å½“å‰æ€»åˆ†: {self.best_score:.4f} (åŸºç¡€: {self.best_base_score:.4f})")
        logging.info(f" ğŸ›¡ï¸ æ£€æŸ¥çŠ¶æ€: {pass_status}")
        logging.info(f" ğŸ“Š æ ¸å¿ƒæŒ‡æ ‡: {stats_msg}")
        logging.info(f" ğŸ“ å½“å‰å…¬å¼: \033[90m{self.best_expr}\033[0m")
        logging.info("\033[93m" + "â•š" + "â•" * 65 + "â•" + "\033[0m")
        logging.info(" ")

    def _print_optimization_summary(self, type_name, count):
        """æ‰“å°ä½ç½®ä¼˜åŒ–æ€»ç»“"""
        # è®¡ç®—é˜¶æ®µæå‡
        # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦è®°å½•è¿›å…¥è¯¥é˜¶æ®µæ—¶çš„åˆ†æ•°ï¼Œä½†ç”±äºçŠ¶æ€åˆ†æ•£ï¼Œæˆ‘ä»¬ç®€åŒ–ä¸ºè®¡ç®—å½“å‰æ€»åˆ†ä¸åˆå§‹åˆ†çš„å·®å€¼
        # æˆ–è€…æ›´å‡†ç¡®åœ°ï¼Œæˆ‘ä»¬åº”è¯¥åœ¨ _optimize_step å¤–éƒ¨è®°å½• start_scoreï¼Œä½†è¿™éœ€è¦æ”¹åŠ¨æ¥å£ã€‚
        # é‰´äºæ—¥å¿—ä¸»è¦æ˜¯ä¸ºäº†çœ‹è¿›åº¦ï¼Œæˆ‘ä»¬æ‰“å°å½“å‰æœ€ä¼˜çŠ¶æ€å³å¯ã€‚
        
        # æ ¼å¼åŒ–æŒ‡æ ‡è¯¦æƒ…
        stats_msg = "æš‚æ— è¯¦ç»†æŒ‡æ ‡"
        pass_status = "æœªçŸ¥"
        display_pc = f"{self.best_pc:.4f}" if self.best_pc is not None else "å¾…è·å–/è·³è¿‡"
        if self.best_stats:
            s = self.best_stats
            pass_status = "é€šè¿‡ âœ…" if s.get('passed') else "å¤±è´¥ âŒ"
            sc_val = f"{s.get('sc'):.4f}" if isinstance(s.get('sc'), (int, float)) else s.get('sc', 'æœªè®¡ç®—')
            stats_msg = (f"Sharpe: {s.get('sharpe', 0):.2f} | Fitness: {s.get('fitness', 0):.2f} | "
                         f"Margin: {s.get('margin', 0):.4f} | SC: {sc_val} | PC: {display_pc}")

        logging.info(" ")
        logging.info(f"\033[95m" + "=" * 20 + f" [ä½ç½®ä¼˜åŒ–æ€»ç»“: {type_name} (å…± {count} ä¸ªä½ç½®)] " + "=" * 20 + "\033[0m")
        logging.info(f"  ğŸš© åˆå§‹ Alpha ID: {self.initial_alpha_id}")
        logging.info(f"  ğŸ† å½“å‰æœ€ä¼˜ Alpha: {self.best_alpha_id}")
        logging.info(f"  ğŸ’° å½“å‰æ€»åˆ†: \033[97m{self.best_score:.4f}\033[0m (åŸºç¡€åˆ†: {self.best_base_score:.4f})")
        # logging.info(f"  ğŸ“ˆ æœ¬æ¬¡ä½ç½®æå‡: ...") # ç”±äºè·¨è¶Šå¤šä¸ªä½ç½®ï¼Œè¿™é‡Œä¸å¥½è®¡ç®—å•æ¬¡æå‡ï¼Œæš‚ç•¥
        total_improvement = self.best_score - self.initial_score
        logging.info(f"  ğŸš€ ç´¯è®¡æ€»æå‡: \033[92m{total_improvement:+.4f}\033[0m")
        logging.info(f"  ğŸ›¡ï¸ æ£€æŸ¥çŠ¶æ€: {pass_status}")
        logging.info(f"  ğŸ“Š è¯¦ç»†æŒ‡æ ‡: {stats_msg}")
        logging.info(f"  ğŸ“ å½“å‰æœ€ä½³å…¬å¼: \033[90m{self.best_expr}\033[0m")
        logging.info(f"\033[95m" + "=" * 75 + "\033[0m")
        logging.info(" ")

    def run(self):
        """è¿è¡Œæ‰€æœ‰Alphaçš„å¼‚æ­¥ä¼˜åŒ–"""
        # æ¨¡å¼1: å¼ºåˆ¶é‡æ–°å¼€å§‹ï¼Œæ— è§†æ—¶é—´ç›´æ¥åˆ é™¤æ‰€æœ‰æ—§æ–‡ä»¶
        if RUN_MODE == 1:
            logging.info("è¿è¡Œæ¨¡å¼1: å¼ºåˆ¶é‡æ–°å¼€å§‹ï¼Œæ­£åœ¨æ¸…ç†æ‰€æœ‰å†å²æ–‡ä»¶...")
            patterns = [r'.*_v4\.[67]\.json$', r'.*_v4\.[67]\.log$', r'checkpoint.*\.json$', r'history.*\.json$']
            try:
                for fname in os.listdir(OUTPUT_DIR):
                    if any(re.match(p, fname) for p in patterns):
                        full_path = os.path.join(OUTPUT_DIR, fname)
                        try:
                            # å°è¯•å…³é—­å¥æŸ„
                            for handler in logging.root.handlers[:]:
                                handler.close()
                                logging.root.removeHandler(handler)
                            os.remove(full_path)
                            logging.info(f"å·²å¼ºåˆ¶åˆ é™¤: {full_path}")
                        except: pass
            except Exception as e:
                logging.warning(f"æ¸…ç†æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
            # é‡æ–°åˆå§‹åŒ–æ—¥å¿— (å› ä¸ºåˆšæ‰å¯èƒ½æŠŠè‡ªå·±çš„æ—¥å¿—æ–‡ä»¶éƒ½åˆ äº†)
            setup_logging()
        else:
            # æ¨¡å¼2æˆ–å…¶ä»–: ä»…æ¸…ç†è¿‡æœŸçš„
            self._cleanup_old_files()
        
        try:
            # æ ¹æ®è¿è¡Œæ¨¡å¼å†³å®šæ˜¯å¦åˆ é™¤æ—§æ–‡ä»¶ï¼ˆæ¨¡å¼2çš„æƒ…å†µï¼‰
            if RUN_MODE == 2:
                logging.info("è¿è¡Œæ¨¡å¼2: æ–­ç‚¹ç»­çˆ¬æ¨¡å¼")
                logging.info("å°†ç›´æ¥åŠ è½½ç°æœ‰æ£€æŸ¥ç‚¹")
                # åŸæœ‰çš„è‡ªåŠ¨æ¸…ç†é€»è¾‘å·²ç§»é™¤ï¼Œä¸¥æ ¼æ‰§è¡Œç»­çˆ¬
                pass

            # é€ä¸ªä¼˜åŒ–Alpha
            for alpha_id in TARGET_ALPHA_IDS:
                try:
                    # ä¸ºæ¯ä¸ªAlphaåˆ›å»ºç‹¬ç«‹çš„æ—¥å¿—è®°å½•å™¨
                    setup_logging(alpha_id)
                    
                    # é‡ç½®ä¼˜åŒ–ä½ç½® (ç¡®ä¿åŒ…å«æ‰€æœ‰é˜¶æ®µçš„ç‹¬ç«‹è®¡æ•°å™¨)
                    self.current_position = {
                        'data_field': START_OPTIMIZATION_FROM.get('data_field', 0),
                        'group': START_OPTIMIZATION_FROM.get('group', 0),
                        'time_window': START_OPTIMIZATION_FROM.get('time_window', 0),
                        'number': START_OPTIMIZATION_FROM.get('number', 0),
                        'operator': START_OPTIMIZATION_FROM.get('operator', 0),
                        'batch_offset': 0,
                        'neutralization': 0,
                        'decay': 0
                    }
                    
                    # è¿­ä»£ä¼˜åŒ–ï¼Œç›´åˆ°æœ€ä½³Alpha IDä¸èµ·å§‹Alpha IDç›¸åŒ
                    current_alpha_id = alpha_id
                    iteration_count = 0
                    
                    while True:
                        iteration_count += 1
                        logging.info(f"å¼€å§‹ç¬¬ {iteration_count} è½®å¼‚æ­¥è¿­ä»£ä¼˜åŒ–ï¼Œèµ·å§‹Alpha ID: {current_alpha_id}")
                        
                        # æ‰§è¡Œå•è½®å¼‚æ­¥ä¼˜åŒ–
                        self.optimize_single_alpha(current_alpha_id)
                        
                        # æ£€æŸ¥æœ€ä½³Alpha IDæ˜¯å¦ä¸èµ·å§‹Alpha IDç›¸åŒ
                        if self.best_alpha_id == current_alpha_id or iteration_count >= MAX_ITERATIONS:
                            logging.info(f"å¼‚æ­¥è¿­ä»£ä¼˜åŒ–å®Œæˆï¼Œæ€»å…±è¿›è¡Œäº† {iteration_count} è½®ä¼˜åŒ–")
                            logging.info(f"æœ€ç»ˆæœ€ä½³Alpha ID: {self.best_alpha_id}")
                            break
                        else:
                            # ä½¿ç”¨æœ€ä½³Alpha IDä½œä¸ºä¸‹ä¸€è½®çš„èµ·å§‹ç‚¹
                            current_alpha_id = self.best_alpha_id
                            logging.info(f"æœ¬è½®å¼‚æ­¥ä¼˜åŒ–ç»“æŸï¼Œæœ€ä½³Alpha IDä¸º {current_alpha_id}ï¼Œå°†ç»§ç»­ä¸‹ä¸€è½®ä¼˜åŒ–")
                            
                            # é‡ç½®ä¼˜åŒ–å™¨çŠ¶æ€ä»¥å‡†å¤‡ä¸‹ä¸€è½®ä¼˜åŒ–
                            self.reset_optimizer_state()
                            
                except KeyboardInterrupt:
                    logging.info(f"å¼‚æ­¥ä¼˜åŒ– Alpha {alpha_id} æ—¶è¢«ç”¨æˆ·ä¸­æ–­ã€‚")
                    raise
                except Exception as e:
                    logging.error(f"å¼‚æ­¥ä¼˜åŒ– Alpha {alpha_id} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                    continue

            logging.info("========== æ‰€æœ‰ Alpha å¼‚æ­¥ä¼˜åŒ–å®Œæˆ ==========")

            # å‘é€æ€»ä½“å®Œæˆé€šçŸ¥é‚®ä»¶
            if EMAIL_CONFIG.get('enabled', False):
                # è·å–æ‰€æœ‰Alphaçš„é€šè¿‡çŠ¶æ€
                passed_info = []
                for alpha_id in TARGET_ALPHA_IDS:
                    alpha_details = self.client.get_alpha_details(alpha_id) if alpha_id else None
                    is_passed = False
                    if alpha_details and 'is' in alpha_details and 'checks' in alpha_details['is']:
                        checks = alpha_details['is']['checks']
                        if checks and not any(c.get('result') == 'FAIL' for c in checks):
                            is_passed = True
                    passed_info.append(f"Alpha {alpha_id}: {'é€šè¿‡' if is_passed else 'æœªé€šè¿‡'}")
                
                subject = "æ‰€æœ‰ Alpha å¼‚æ­¥å›æµ‹ä»»åŠ¡å·²å®Œæˆ"
                content = f"""æ‚¨çš„æ‰€æœ‰ Alpha å¼‚æ­¥å›æµ‹ä»»åŠ¡å·²ç»å…¨éƒ¨å®Œæˆï¼

ä¼˜åŒ–çš„ Alpha IDs: {TARGET_ALPHA_IDS}
æ£€æŸ¥é€šè¿‡æƒ…å†µ:
{'\n'.join(passed_info)}

è¯¦ç»†ç»“æœè¯·æŸ¥çœ‹å„Alphaå¯¹åº”æ—¥å¿—æ–‡ä»¶: {[os.path.join(OUTPUT_DIR, f'{alpha_id}_hill_climbing_v4.7.log') for alpha_id in TARGET_ALPHA_IDS]}
"""
                send_qq_email(subject, content)

        except KeyboardInterrupt:
            logging.info("å¼‚æ­¥ç¨‹åºå·²è¢«ç”¨æˆ·ä¸­æ–­ã€‚")
        except Exception as e:
            logging.error(f"å¼‚æ­¥è¿è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿæœªé¢„æœŸçš„é”™è¯¯: {e}")
            # å‘é€é”™è¯¯é€šçŸ¥é‚®ä»¶
            if EMAIL_CONFIG.get('enabled', False):
                subject = "Alpha å¼‚æ­¥å›æµ‹ä»»åŠ¡å‡ºç°é”™è¯¯"
                content = f"æ‚¨çš„ Alpha å¼‚æ­¥å›æµ‹ä»»åŠ¡åœ¨è¿è¡Œè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}"
                send_qq_email(subject, content)

    def reset_optimizer_state(self):
        """é‡ç½®ä¼˜åŒ–å™¨çŠ¶æ€ä»¥å‡†å¤‡ä¸‹ä¸€è½®è¿­ä»£"""
        # é‡ç½®å½“å‰ä¼˜åŒ–ä½ç½®
        self.current_position = {
            'data_field': START_OPTIMIZATION_FROM.get('data_field', 0),
            'group': START_OPTIMIZATION_FROM.get('group', 0),
            'time_window': START_OPTIMIZATION_FROM.get('time_window', 0),
            'number': START_OPTIMIZATION_FROM.get('number', 0),
            'operator': START_OPTIMIZATION_FROM.get('operator', 0),
            'batch_offset': 0,
            'neutralization': 0,
            'decay': 0
        }
        
        # é‡ç½®åˆå§‹åˆ†æ•°å’ŒIDä¸ºå½“å‰æœ€ä½³å€¼ï¼Œå› ä¸ºä¸‹ä¸€è½®å°†ä»¥å½“å‰æœ€ä½³ä¸ºèµ·ç‚¹
        self.initial_score = self.best_score
        self.initial_alpha_id = self.best_alpha_id
        
        # ä¿å­˜æ£€æŸ¥ç‚¹
        if self.best_alpha_id:
            self.save_checkpoint(self.best_alpha_id)


if __name__ == '__main__':


    print("==================================================")


    print("ğŸš€ è„šæœ¬å·²å¯åŠ¨ï¼Œæ­£åœ¨åˆå§‹åŒ–ä¼˜åŒ–å™¨...")


    print("==================================================")


    try:


        optimizer = AsyncOptimizer()


        print("âœ… åˆå§‹åŒ–æˆåŠŸï¼Œå¼€å§‹æ‰§è¡Œä¼˜åŒ–ä»»åŠ¡...")


        optimizer.run()


    except Exception as e:


        print(f"âŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")


        import traceback


        traceback.print_exc()
