import pandas as pd
import json
import time
import os
from datetime import datetime
from machine_lib import login

class AlphaDetailFetcher:
    """Alphaè¯¦ç»†ä¿¡æ¯è·å–å™¨ - æ”¯æŒæ‰¹é‡å¤„ç†ï¼ˆä¿®å¤ç±»å±æ€§é—®é¢˜ï¼‰"""
   
    # ========== å…³é”®ä¿®å¤ï¼šå°†brain_api_urlå®šä¹‰ä¸ºç±»å±æ€§ ==========
    brain_api_url = "https://api.worldquantbrain.com"
    _session = None
    _session_time = None
   
    @classmethod
    def get_session(cls):
        """è·å–æˆ–åˆ›å»ºä¼šè¯ - å¢åŠ ç™»å½•æ ¡éªŒï¼ˆä¿®å¤brain_api_urlè®¿é—®ï¼‰"""
        if cls._session is None or cls._session_time is None:
            cls._session = login()
            # æ–°å¢ï¼šæ ¡éªŒç™»å½•æ˜¯å¦æˆåŠŸ
            if cls._session is None:
                print("âŒ ç™»å½•å¤±è´¥ï¼šè¿”å›ç©ºä¼šè¯")
                raise Exception("INVALID_CREDENTIALS - ç™»å½•å‡­è¯æ— æ•ˆ")
            
            # éªŒè¯ä¼šè¯æœ‰æ•ˆæ€§ï¼ˆç°åœ¨èƒ½æ­£ç¡®è®¿é—®ç±»å±æ€§cls.brain_api_urlï¼‰
            try:
                test_response = cls._session.get(f"{cls.brain_api_url}/user/me")
                if test_response.status_code == 401:
                    raise Exception("INVALID_CREDENTIALS - ä¼šè¯æœªæˆæƒ")
            except Exception as e:
                print(f"âŒ ä¼šè¯éªŒè¯å¤±è´¥ï¼š{e}")
                raise
            
            cls._session_time = time.time()
            print("ğŸ”„ åˆ›å»ºæ–°ä¼šè¯ï¼ˆéªŒè¯é€šè¿‡ï¼‰")
        else:
            elapsed = time.time() - cls._session_time
            if elapsed > 4 * 3600:
                print("ğŸ”„ ä¼šè¯è¿‡æœŸï¼Œåˆ›å»ºæ–°ä¼šè¯")
                cls._session = login()
                cls._session_time = time.time()
            else:
                print(f"â™»ï¸ å¤ç”¨ä¼šè¯ (å·²ä½¿ç”¨ {elapsed/3600:.1f} å°æ—¶)")
       
        return cls._session
   
    def __init__(self):
        """åˆå§‹åŒ–è·å–å™¨ï¼ˆç§»é™¤å®ä¾‹å±æ€§brain_api_urlï¼‰"""
        self.session = self.get_session()
        # æ‰¹é‡å¤„ç†çš„ç»“æœå­˜å‚¨
        self.batch_results = []
   
    def get_alpha_details(self, alpha_id):
        """è·å–å•ä¸ªAlphaè¯¦ç»†ä¿¡æ¯"""
        print(f"\nğŸ“¡ è·å–Alpha: {alpha_id}")
       
        # è·å–åŸºæœ¬æ•°æ®
        base_details = self._get_base_alpha_data(alpha_id)
        if not base_details:
            print(f"âŒ Alpha {alpha_id} åŸºç¡€æ•°æ®è·å–å¤±è´¥ï¼Œè·³è¿‡")
            return None
       
        # è·å–ç›¸å…³æ€§æ•°æ® - ä½¿ç”¨ç¨³å¥çš„æ–¹æ³•
        correlation_data = self._get_correlation_data_robust(alpha_id)
       
        # åˆå¹¶æ•°æ®
        if correlation_data:
            base_details.update(correlation_data)
       
        return base_details
   
    def _get_base_alpha_data(self, alpha_id):
        """è·å–åŸºæœ¬Alphaæ•°æ®"""
        try:
            # è®¿é—®ç±»å±æ€§ï¼šself.__class__.brain_api_url æˆ– AlphaDetailFetcher.brain_api_url
            response = self.session.get(f"{self.__class__.brain_api_url}/alphas/{alpha_id}")
           
            if response.status_code == 200:
                alpha_data = response.json()
                print("âœ… åŸºç¡€æ•°æ®è·å–æˆåŠŸ")
                return self._parse_base_data(alpha_data)
            elif response.status_code == 404:
                print(f"âŒ Alpha {alpha_id} ä¸å­˜åœ¨")
                return None
            elif response.status_code == 429:
                print(f"âš ï¸ åŸºç¡€æ•°æ®è¯·æ±‚è§¦å‘é€Ÿç‡é™åˆ¶ (429)ï¼Œç­‰å¾…10ç§’åé‡è¯•")
                time.sleep(10)
                return self._get_base_alpha_data(alpha_id)  # é‡è¯•ä¸€æ¬¡
            else:
                print(f"âš ï¸ åŸºç¡€æ•°æ®è¯·æ±‚å¤±è´¥ ({response.status_code})")
                return None
               
        except Exception as e:
            print(f"âŒ åŸºç¡€æ•°æ®è¯·æ±‚å‡ºé”™: {str(e)}")
            return None
   
    def _get_correlation_data_robust(self, alpha_id):
        """ç¨³å¥è·å–ç›¸å…³æ€§æ•°æ® - å»¶é•¿å†…éƒ¨å»¶è¿Ÿ"""
        correlation_data = {}
       
        # é€ä¸ªè·å–ç›¸å…³æ€§æ•°æ®ï¼Œå»¶é•¿å»¶è¿Ÿè‡³1ç§’é¿å…è¯·æ±‚è¿‡å¿«
        correlation_data['Self_Correlation'] = self._get_correlation_with_retry(alpha_id, "self")
        time.sleep(1)  # å»¶é•¿å»¶è¿Ÿ
       
        correlation_data['Power_Pool_Correlation'] = self._get_correlation_with_retry(alpha_id, "power-pool")
        time.sleep(1)  # å»¶é•¿å»¶è¿Ÿ
       
        correlation_data['Prod_Correlation'] = self._get_correlation_with_retry(alpha_id, "prod")
       
        return correlation_data
   
    def _get_correlation_with_retry(self, alpha_id, corr_type):
        """å¸¦é‡è¯•çš„è·å–ç›¸å…³æ€§å€¼ - å¢å¼º429å¤„ç†"""
        # è®¿é—®ç±»å±æ€§
        url = f"{self.__class__.brain_api_url}/alphas/{alpha_id}/correlations/{corr_type}"
       
        for retry in range(3):
            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
                    'Accept': 'application/json',
                    'Accept-Language': 'en-US,en;q=0.9',
                }
               
                response = self.session.get(url, headers=headers, timeout=30)
               
                print(f"ğŸ” {corr_type.upper()} APIçŠ¶æ€: {response.status_code}")
               
                if response.status_code == 200:
                    content = response.text.strip()
                   
                    if not content or content == "null":
                        print(f"âš ï¸  {corr_type.upper()}: ç©ºå“åº”")
                        time.sleep(3)
                        continue
                   
                    value = self._extract_correlation_value(content, corr_type)
                    if value is not None:
                        print(f"âœ…  {corr_type.upper()}: {value}")
                        return value
                    else:
                        print(f"âš ï¸  {corr_type.upper()}: æ— æ³•æå–å€¼, å†…å®¹: {content[:100]}")
               
                elif response.status_code == 404:
                    print(f"âš ï¸  {corr_type.upper()} APIä¸å­˜åœ¨ (404)")
                    break
               
                elif response.status_code == 429:
                    # æŒ‡æ•°é€€é¿ç­‰å¾…
                    retry_after = response.headers.get('Retry-After', 5 * (retry + 1))
                    wait_time = int(retry_after) + 10
                    print(f"â³  {corr_type.upper()} é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’ (é‡è¯• {retry+1}/3)")
                    time.sleep(wait_time)
                    continue
               
                elif response.status_code == 401:
                    print(f"âŒ  {corr_type.upper()} æœªæˆæƒï¼Œé‡æ–°ç™»å½•")
                    self.__class__._session = None
                    self.__class__._session_time = None
                    self.session = self.get_session()
                    time.sleep(5)
                    continue
               
                else:
                    print(f"âš ï¸  {corr_type.upper()} è¯·æ±‚å¤±è´¥ ({response.status_code})")
               
                # æŒ‡æ•°é€€é¿ç­‰å¾…
                wait_time = 2 **(retry + 1)
                print(f"â³  é‡è¯•å‰ç­‰å¾… {wait_time} ç§’ (é‡è¯• {retry+1}/3)")
                time.sleep(wait_time)
               
            except Exception as e:
                print(f"âŒ  {corr_type.upper()} è¯·æ±‚å‡ºé”™: {str(e)}")
                wait_time = 3 * (retry + 1)
                time.sleep(wait_time)
       
        print(f"âŒ  è·å–{corr_type.upper()}å¤±è´¥")
        return 'N/A'
   
    def _extract_correlation_value(self, content, corr_type):
        """ä»å“åº”å†…å®¹ä¸­æå–ç›¸å…³æ€§å€¼"""
        # æ–¹æ³•1: å°è¯•è§£æJSON
        try:
            data = json.loads(content)
           
            if isinstance(data, dict):
                for key in ['value', 'max', 'correlation', 'corr', 'result']:
                    if key in data and data[key] is not None:
                        value = data[key]
                        if isinstance(value, (int, float)):
                            return float(value)
                for key, val in data.items():
                    if isinstance(val, (int, float)):
                        return float(val)
           
            elif isinstance(data, (int, float)):
                return float(data)
           
            elif isinstance(data, list) and len(data) > 0:
                first_item = data[0]
                if isinstance(first_item, dict):
                    for key in ['value', 'max', 'correlation']:
                        if key in first_item and first_item[key] is not None:
                            value = first_item[key]
                            if isinstance(value, (int, float)):
                                return float(value)
                elif isinstance(first_item, (int, float)):
                    return float(first_item)
       
        except json.JSONDecodeError:
            pass
       
        # æ–¹æ³•2: å°è¯•ç›´æ¥æå–æ•°å­—
        try:
            return float(content)
        except:
            pass
       
        # æ–¹æ³•3: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–æ•°å­—
        import re
        matches = re.findall(r'-?\d+\.?\d*', content)
        if matches:
            try:
                return float(matches[0])
            except:
                pass
       
        # æ–¹æ³•4: æŸ¥æ‰¾ç™¾åˆ†æ¯”
        percent_match = re.search(r'(\d+\.?\d*)%', content)
        if percent_match:
            try:
                return float(percent_match.group(1)) / 100
            except:
                pass
       
        return None
   
    def _parse_base_data(self, alpha_data):
        """è§£æåŸºç¡€Alphaæ•°æ®"""
        details = {}
       
        try:
            # 1. åŸºæœ¬ä¿¡æ¯
            details['Alpha_ID'] = alpha_data.get('id', 'N/A')
            details['Code'] = alpha_data.get('regular', {}).get('code', 'N/A')
            details['Color'] = alpha_data.get('color', 'None')
            details['Status'] = alpha_data.get('status', 'N/A')
            details['Date_Created'] = alpha_data.get('dateCreated', 'N/A')
           
            # 2. æ¨¡æ‹Ÿè®¾ç½®
            settings = alpha_data.get('settings', {})
            details['Region'] = settings.get('region', 'N/A')
            details['Universe'] = settings.get('universe', 'N/A')
            details['Delay'] = settings.get('delay', 'N/A')
            details['Decay'] = settings.get('decay', 'N/A')
            details['Neutralization'] = settings.get('neutralization', 'N/A')
            details['Truncation'] = settings.get('truncation', 'N/A')
            details['Start_Date'] = settings.get('startDate', 'N/A')
            details['End_Date'] = settings.get('endDate', 'N/A')
           
            # 3. IS Summaryæ•°æ®
            is_data = alpha_data.get('is', {})
            details['IS_Sharpe'] = is_data.get('sharpe', 0)
            details['IS_Turnover'] = is_data.get('turnover', 0)
            details['IS_Fitness'] = is_data.get('fitness', 0)
            details['IS_Returns'] = is_data.get('returns', 0)
            details['IS_Drawdown'] = is_data.get('drawdown', 0)
            details['IS_Margin'] = is_data.get('margin', 0)
            details['IS_Pnl'] = is_data.get('pnl', 0)
           
            # 4. Investability Constrainedæ•°æ®
            inv_data = is_data.get('investabilityConstrained', {})
            details['INV_Sharpe'] = inv_data.get('sharpe', 0)
            details['INV_Turnover'] = inv_data.get('turnover', 0)
            details['INV_Fitness'] = inv_data.get('fitness', 0)
            details['INV_Returns'] = inv_data.get('returns', 0)
            details['INV_Drawdown'] = inv_data.get('drawdown', 0)
            details['INV_Margin'] = inv_data.get('margin', 0)
            details['INV_Pnl'] = inv_data.get('pnl', 0)
           
            # 5. å…¶ä»–é‡è¦æ•°æ®
            checks = is_data.get('checks', [])
            check_values = {}
            for check in checks:
                name = check.get('name', '')
                value = check.get('value', None)
                if value is not None:
                    check_values[name] = value
           
            details['Low_Robust_Sharpe'] = check_values.get('LOW_ROBUST_UNIVERSE_SHARPE', 0)
            details['Concentrated_Weight'] = 'PASS' if 'CONCENTRATED_WEIGHT' in check_values else 'N/A'
            details['Sub_Universe_Sharpe'] = check_values.get('LOW_SUB_UNIVERSE_SHARPE', 0)
            details['Two_Year_Sharpe'] = check_values.get('LOW_2Y_SHARPE', 0)
           
            # 6. æ ‡ç­¾
            details['Tags'] = ', '.join(alpha_data.get('tags', []))
           
        except Exception as e:
            print(f"âŒ è§£æåŸºç¡€æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return None
       
        return details
   
    def display_results(self, details):
        """æ˜¾ç¤ºå•ä¸ªAlphaçš„ç»“æœ"""
        if not details:
            print("âŒ æ— æ•°æ®å¯æ˜¾ç¤º")
            return
       
        print("\n" + "â•" * 60)
        print(f"ğŸ“Š ALPHAè¯¦æƒ…æŠ¥å‘Š: {details['Alpha_ID']}")
        print("â•" * 60)
       
        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ†” ID: {details['Alpha_ID']}")
        print(f"ğŸ¨ é¢œè‰²: {details['Color']} | ğŸ“ çŠ¶æ€: {details['Status']}")
        print(f"ğŸ“ åœ°åŒº: {details['Region']} | ğŸŒ è‚¡ç¥¨æ± : {details['Universe']}")
        print(f"ğŸ“… æœŸé—´: {details['Start_Date']} è‡³ {details['End_Date']}")
        print("â”€" * 40)
       
        # IS Summaryæ•°æ®è¡¨æ ¼
        print("ğŸ“ˆ IS Summary Aggregate Data")
        print("â”€" * 25)
       
        is_metrics = [
            ('Sharpe', details.get('IS_Sharpe', 0), 'float'),
            ('Turnover', details.get('IS_Turnover', 0), 'percent'),
            ('Fitness', details.get('IS_Fitness', 0), 'float'),
            ('Returns', details.get('IS_Returns', 0), 'percent'),
            ('Drawdown', details.get('IS_Drawdown', 0), 'percent'),
            ('Margin', details.get('IS_Margin', 0), 'basis')
        ]
       
        for name, value, fmt in is_metrics:
            formatted = self._format_value(value, fmt)
            print(f"{name:12} {formatted:>15}")
       
        print("â”€" * 40)
       
        # Investability Constrainedæ•°æ®è¡¨æ ¼
        print("ğŸ“‰ Investability Constrained Aggregate Data")
        print("â”€" * 25)
       
        inv_metrics = [
            ('Sharpe', details.get('INV_Sharpe', 0), 'float'),
            ('Turnover', details.get('INV_Turnover', 0), 'percent'),
            ('Fitness', details.get('INV_Fitness', 0), 'float'),
            ('Returns', details.get('INV_Returns', 0), 'percent'),
            ('Drawdown', details.get('INV_Drawdown', 0), 'percent'),
            ('Margin', details.get('INV_Margin', 0), 'basis')
        ]
       
        for name, value, fmt in inv_metrics:
            formatted = self._format_value(value, fmt)
            print(f"{name:12} {formatted:>15}")
       
        print("â”€" * 40)
       
        # ç›¸å…³æ€§æ•°æ®
        print("ğŸ”— ç›¸å…³æ€§æ•°æ®")
        print("â”€" * 25)
       
        corr_metrics = [
            ('Self Correlation', details.get('Self_Correlation', 'N/A')),
            ('Power Pool Correlation', details.get('Power_Pool_Correlation', 'N/A')),
            ('Prod Correlation', details.get('Prod_Correlation', 'N/A'))
        ]
       
        for name, value in corr_metrics:
            formatted = self._format_correlation(value)
            print(f"{name:25} {formatted:>10}")
       
        print("â”€" * 40)
       
        # å…¶ä»–é‡è¦æŒ‡æ ‡
        print("ğŸ“Š å…¶ä»–é‡è¦æŒ‡æ ‡")
        print("â”€" * 25)
       
        other_metrics = [
            ('Low Robust Sharpe', details.get('Low_Robust_Sharpe', 0), 'float'),
            ('Sub Universe Sharpe', details.get('Sub_Universe_Sharpe', 0), 'float'),
            ('Two Year Sharpe', details.get('Two_Year_Sharpe', 0), 'float'),
            ('Concentrated Weight', details.get('Concentrated_Weight', 'N/A'), 'str'),
            ('Decay', details.get('Decay', 'N/A'), 'str'),
            ('Neutralization', details.get('Neutralization', 'N/A'), 'str'),
            ('Truncation', details.get('Truncation', 'N/A'), 'percent')
        ]
       
        for name, value, fmt in other_metrics:
            formatted = self._format_value(value, fmt)
            print(f"{name:25} {formatted:>10}")
       
        print("â•" * 60)
   
    def _format_correlation(self, value):
        """æ ¼å¼åŒ–ç›¸å…³æ€§å€¼"""
        if value in ['N/A', None, '', 'PENDING']:
            return 'N/A'
       
        try:
            if isinstance(value, str):
                value = float(value)
           
            return f"{value * 100:.2f}%"
        except:
            return str(value)
   
    def _format_value(self, value, fmt_type):
        """æ ¼å¼åŒ–æ•°å€¼"""
        if value in ['N/A', None, '', 'PENDING', 'PASS']:
            return str(value)
       
        try:
            if fmt_type == 'percent':
                num_value = float(value)
                return f"{num_value * 100:.2f}%"
            elif fmt_type == 'basis':
                num_value = float(value)
                return f"{num_value * 10000:.2f}â€±"
            elif fmt_type == 'float':
                num_value = float(value)
                return f"{num_value:.2f}"
            elif fmt_type == 'str':
                return str(value)
            else:
                return str(value)
        except:
            return str(value)
   
    def save_to_csv(self, details, filename=None, is_batch=False):
        """ä¿å­˜å•ä¸ªAlphaæ•°æ®åˆ°CSV - æ”¯æŒæ‰¹é‡æ ‡è®°"""
        if not details:
            return None
       
        os.makedirs("alpha_details", exist_ok=True)
       
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            if is_batch:
                filename = f"alpha_{details['Alpha_ID']}_batch_{timestamp}.csv"
            else:
                filename = f"alpha_{details['Alpha_ID']}_{timestamp}.csv"
       
        filepath = os.path.join("alpha_details", filename)
       
        try:
            df = pd.DataFrame([details])
           
            column_order = [
                'Alpha_ID', 'Status', 'Color', 'Date_Created', 'Tags',
                'Region', 'Universe', 'Delay', 'Decay', 'Neutralization', 'Truncation',
                'Start_Date', 'End_Date',
                'IS_Sharpe', 'IS_Turnover', 'IS_Fitness', 'IS_Returns',
                'IS_Drawdown', 'IS_Margin', 'IS_Pnl',
                'INV_Sharpe', 'INV_Turnover', 'INV_Fitness', 'INV_Returns',
                'INV_Drawdown', 'INV_Margin', 'INV_Pnl',
                'Self_Correlation', 'Power_Pool_Correlation', 'Prod_Correlation',
                'Low_Robust_Sharpe', 'Sub_Universe_Sharpe', 'Two_Year_Sharpe',
                'Concentrated_Weight', 'Code'
            ]
           
            existing_cols = [col for col in column_order if col in df.columns]
            df = df[existing_cols]
           
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ å•ä¸ªAlphaæ•°æ®å·²ä¿å­˜: {filepath}")
           
            return filepath
           
        except Exception as e:
            print(f"âŒ ä¿å­˜CSVå¤±è´¥: {str(e)}")
            return None
    
    def save_batch_results(self):
        """ä¿å­˜æ‰¹é‡å¤„ç†çš„æ‰€æœ‰Alphaæ•°æ®åˆ°ä¸€ä¸ªCSVæ–‡ä»¶"""
        if not self.batch_results:
            print("âŒ æ— æ‰¹é‡æ•°æ®å¯ä¿å­˜")
            return None
        
        os.makedirs("alpha_details", exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"alpha_batch_results_{timestamp}.csv"
        filepath = os.path.join("alpha_details", filename)
        
        try:
            # è¿‡æ»¤æ‰Noneçš„ç»“æœ
            valid_results = [res for res in self.batch_results if res is not None]
            if not valid_results:
                print("âŒ æ— æœ‰æ•ˆæ‰¹é‡æ•°æ®å¯ä¿å­˜")
                return None
            
            df = pd.DataFrame(valid_results)
            
            # ç»Ÿä¸€åˆ—é¡ºåº
            column_order = [
                'Alpha_ID', 'Status', 'Color', 'Date_Created', 'Tags',
                'Region', 'Universe', 'Delay', 'Decay', 'Neutralization', 'Truncation',
                'Start_Date', 'End_Date',
                'IS_Sharpe', 'IS_Turnover', 'IS_Fitness', 'IS_Returns',
                'IS_Drawdown', 'IS_Margin', 'IS_Pnl',
                'INV_Sharpe', 'INV_Turnover', 'INV_Fitness', 'INV_Returns',
                'INV_Drawdown', 'INV_Margin', 'INV_Pnl',
                'Self_Correlation', 'Power_Pool_Correlation', 'Prod_Correlation',
                'Low_Robust_Sharpe', 'Sub_Universe_Sharpe', 'Two_Year_Sharpe',
                'Concentrated_Weight', 'Code'
            ]
            
            existing_cols = [col for col in column_order if col in df.columns]
            df = df[existing_cols]
            
            df.to_csv(filepath, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ æ‰¹é‡æ•°æ®æ±‡æ€»å·²ä¿å­˜: {filepath}")
            
            return filepath
        
        except Exception as e:
            print(f"âŒ ä¿å­˜æ‰¹é‡CSVå¤±è´¥: {str(e)}")
            return None


def fetch_alpha_details(alpha_id, fetcher=None):
    """è·å–å•ä¸ªAlphaè¯¦æƒ…ï¼ˆå…¼å®¹æ‰¹é‡å¤„ç†ï¼‰"""
    if fetcher is None:
        fetcher = AlphaDetailFetcher()
    
    details = fetcher.get_alpha_details(alpha_id)
    
    if details:
        # æ˜¾ç¤ºç»“æœ
        fetcher.display_results(details)
        # ä¿å­˜å•ä¸ªæ–‡ä»¶
        fetcher.save_to_csv(details, is_batch=True)
        # æ·»åŠ åˆ°æ‰¹é‡ç»“æœåˆ—è¡¨
        fetcher.batch_results.append(details)
    else:
        fetcher.batch_results.append(None)
    
    return details


def fetch_batch_alpha_details(alpha_ids, batch_delay=5):
    """æ‰¹é‡è·å–å¤šä¸ªAlphaè¯¦æƒ…"""
    print("=" * 70)
    print("ğŸ§  Brainå¹³å°Alphaæ‰¹é‡è¯¦æƒ…æŸ¥è¯¢å·¥å…·")
    print("=" * 70)
    print(f"ğŸ¯ å¾…å¤„ç†Alphaæ•°é‡: {len(alpha_ids)}")
    print(f"â±ï¸  Alphaä¹‹é—´å»¶è¿Ÿ: {batch_delay} ç§’")
    print("=" * 70)
    
    # åˆ›å»ºå•ä¸ªfetcherå®ä¾‹ï¼ˆå¤ç”¨ä¼šè¯ï¼‰
    fetcher = AlphaDetailFetcher()
    success_count = 0
    fail_count = 0
    
    for idx, alpha_id in enumerate(alpha_ids, 1):
        print(f"\n{'='*20} å¤„ç†ç¬¬ {idx}/{len(alpha_ids)} ä¸ªAlpha {'='*20}")
        try:
            details = fetch_alpha_details(alpha_id, fetcher)
            if details:
                success_count += 1
            else:
                fail_count += 1
        except Exception as e:
            print(f"âŒ å¤„ç†Alpha {alpha_id} æ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
            fail_count += 1
            fetcher.batch_results.append(None)
        
        # æœ€åä¸€ä¸ªAlphaä¸æ·»åŠ å»¶è¿Ÿ
        if idx < len(alpha_ids):
            print(f"\nâ³ ç­‰å¾… {batch_delay} ç§’åå¤„ç†ä¸‹ä¸€ä¸ªAlpha...")
            time.sleep(batch_delay)
    
    # ä¿å­˜æ‰¹é‡æ±‡æ€»æ–‡ä»¶
    batch_file = fetcher.save_batch_results()
    
    # è¾“å‡ºæ‰¹é‡å¤„ç†ç»Ÿè®¡
    print("\n" + "="*70)
    print("ğŸ“Š æ‰¹é‡å¤„ç†å®Œæˆç»Ÿè®¡")
    print("="*70)
    print(f"âœ… æˆåŠŸ: {success_count} ä¸ª")
    print(f"âŒ å¤±è´¥: {fail_count} ä¸ª")
    print(f"ğŸ“„ æ€»è®¡: {len(alpha_ids)} ä¸ª")
    if batch_file:
        print(f"ğŸ“ æ‰¹é‡æ±‡æ€»æ–‡ä»¶: {batch_file}")
    print("="*70)
    
    return fetcher.batch_results


def main():
    """ä¸»å‡½æ•° - æ”¯æŒæ‰¹é‡å¤„ç†"""
    # ============================================
    # â­â­â­ åœ¨è¿™é‡Œè®¾ç½®å¤šä¸ªAlpha ID â­â­â­
    # ============================================
    ALPHA_IDS = [
        "Jj0booLe",  # ç¤ºä¾‹Alpha ID 1
        "RRZdl3Ob",  # ç¤ºä¾‹Alpha ID 2
        "0rvY7wx",   # ç¤ºä¾‹Alpha ID 3
        "RZdlgwj",
        "Gr0kzXzO",
        "e78Lv9zz",
        "O0wog72R"
    ]
    # æ‰¹é‡å¤„ç†æ—¶æ¯ä¸ªAlphaä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰ï¼Œå»ºè®®5-10ç§’
    BATCH_DELAY = 5
    # ============================================
    
    # æ‰¹é‡æ¨¡å¼
    batch_results = fetch_batch_alpha_details(ALPHA_IDS, BATCH_DELAY)
    
    return batch_results


if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œ
    main()
