"""
WorldQuant Brain æ‰¹é‡Alphaç”Ÿæˆ - å®Œæ•´æ“ä½œç¬¦ç‰ˆæœ¬
ä¿®å¤ï¼š
1. è§£å†³400 Bad Requestï¼ˆMulti-simulationsæ ¼å¼é”™è¯¯ï¼‰
2. ä»»åŠ¡å¤±è´¥è‡ªåŠ¨è·³è¿‡ï¼Œç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªä»»åŠ¡
3. å¢å¼ºå¼‚å¸¸å¤„ç†ï¼Œé¿å…ç¨‹åºå¡ä½
"""

import sys
import random
import time
sys.path.append('.')
from machine_lib_0GLB import *

# ============================= é…ç½®åŒºåŸŸ =============================
# å…¨å±€ç™»å½•Sessionï¼ˆç¡®ä¿æ•´ä¸ªç¨‹åºä½¿ç”¨åŒä¸€ä¸ªSessionï¼‰
s = None

# æ•°æ®é›†é…ç½®
DATASET_ID = 'analyst69'                 
REGION = 'GLB'                           
UNIVERSE = 'MINVOL1M'                    
DELAY = 1                                
DATA_TYPE = 'MATRIX'                     

# æ¨¡æ‹Ÿé…ç½®ï¼ˆå…³é”®ï¼šé™ä½å¹¶å‘ï¼Œå‡å°‘è¯·æ±‚é¢‘ç‡ï¼‰
NEUTRALIZATIONS =  ["NONE", "REVERSION_AND_MOMENTUM", "STATISTICAL", "CROWDING", "FAST", "SLOW", "MARKET", "SECTOR", "INDUSTRY", "SUBINDUSTRY", "COUNTRY","SLOW_AND_FAST"]
random.shuffle(NEUTRALIZATIONS)
INIT_DECAY = 60                           
TASK_POOL_SIZE = 1  # å•ä»»åŠ¡æ¨¡å¼ï¼ˆä¿®å¤400é”™è¯¯å…³é”®ï¼‰
CONCURRENT_SIMS = 1  

# å­—æ®µèŒƒå›´
FIELD_RANGE_SIZE = 20  

# ============================= æ ¸å¿ƒä¿®å¤ï¼šè¡¨è¾¾å¼ç”Ÿæˆå™¨ä¿æŒä¸å˜ =============================
class AlphaExpressionGenerator:
    """æ™ºèƒ½Alphaè¡¨è¾¾å¼ç”Ÿæˆå™¨ - æ”¯æŒæ‰€æœ‰151ä¸ªæ“ä½œç¬¦"""
    
    def __init__(self, fields, data_type='MATRIX'):
        self.fields = fields
        self.data_type = data_type
        self.expressions = []
    
    def generate_all(self):
        """ç”Ÿæˆæ‰€æœ‰ç±»å‹çš„è¡¨è¾¾å¼"""
        print(f"\n[è¡¨è¾¾å¼ç”Ÿæˆ] å¼€å§‹ç”Ÿæˆ...")
        print(f"  å­—æ®µæ•°: {len(self.fields)}")
        print(f"  æ•°æ®ç±»å‹: {self.data_type}")
        
        # 1. å•å‚æ•°æ“ä½œç¬¦ (46ä¸ª)
        self._generate_single_param()
        print(f"  âœ“ å•å‚æ•°æ“ä½œç¬¦: {len([op for op in basic_ops if op in basic_ops])}ä¸ª")
        
        # 2. æ—¶é—´åºåˆ—æ“ä½œç¬¦ (åŒå‚æ•°ï¼Œéœ€è¦çª—å£æœŸ)
        self._generate_ts_operators()
        print(f"  âœ“ æ—¶é—´åºåˆ—æ“ä½œç¬¦: {len([op for op in ts_ops if op.startswith('ts_')])}ä¸ª")
        
        # 3. Tailç±»æ“ä½œç¬¦
        self._generate_tail_operators()
        print(f"  âœ“ Tailç±»æ“ä½œç¬¦")
        
        # 3.5. Bucketæ“ä½œç¬¦ï¼ˆéœ€è¦å‘½åå‚æ•°ï¼‰
        self._generate_bucket_operators()
        print(f"  âœ“ Bucketæ“ä½œç¬¦")
        
        # 3.6. Truncate & Winsorizeæ“ä½œç¬¦ï¼ˆéœ€è¦å‘½åå‚æ•°ï¼‰
        self._generate_truncate_winsorize_operators()
        print(f"  âœ“ Truncate & Winsorizeæ“ä½œç¬¦")
        
        # 3.7. Clampæ“ä½œç¬¦ï¼ˆéœ€è¦å‘½åå‚æ•°ï¼‰
        self._generate_clamp_operators()
        print(f"  âœ“ Clampæ“ä½œç¬¦")
        
        # 3.8. TS Target TVRç³»åˆ—æ“ä½œç¬¦ï¼ˆéœ€è¦å®Œæ•´å‘½åå‚æ•°ï¼‰
        self._generate_ts_target_tvr_operators()
        print(f"  âœ“ TS Target TVRæ“ä½œç¬¦")
        
        # 3.9. Densifyæ“ä½œç¬¦ï¼ˆç”¨äºåˆ†ç»„å­—æ®µä¼˜åŒ–ï¼‰
        self._generate_densify_operators()
        print(f"  âœ“ Densifyæ“ä½œç¬¦")
        
        # 4. åˆ†ç»„æ“ä½œç¬¦ (åŒå‚æ•°ï¼Œéœ€è¦åˆ†ç»„å­—æ®µ)
        self._generate_group_operators()
        print(f"  âœ“ åˆ†ç»„æ“ä½œç¬¦: {len([op for op in basic_ops if op.startswith('group_')])}ä¸ª")
        
        # 5. åŒå­—æ®µç®—æœ¯/é€»è¾‘æ“ä½œç¬¦
        if len(self.fields) >= 2:
            self._generate_dual_field()
            print(f"  âœ“ åŒå­—æ®µæ“ä½œç¬¦")
        
        # 6. ä¸‰å‚æ•°æ“ä½œç¬¦ï¼ˆç²¾é€‰ï¼‰
        self._generate_triple_param()
        print(f"  âœ“ ä¸‰å‚æ•°æ“ä½œç¬¦: {len([op for op in basic_ops if op in ['ts_corr', 'ts_covariance', 'if_else']])}ä¸ª")
        
        print(f"\n  æ€»è¡¨è¾¾å¼æ•°: {len(self.expressions)}")
        return self.expressions
    
    def _get_field_expr(self, field):
        """è·å–å­—æ®µè¡¨è¾¾å¼ï¼ˆVECTORéœ€è¦å…ˆè½¬æ¢ï¼‰"""
        if self.data_type == 'VECTOR':
            vec_op = random.choice([
                'vec_avg', 'vec_sum', 'vec_max', 'vec_min', 'vec_count', 'vec_stddev', 'vec_norm'
            ])
            return f'{vec_op}({field})'
        return field
    
    def _generate_single_param(self):
        """ç”Ÿæˆå•å‚æ•°æ“ä½œç¬¦è¡¨è¾¾å¼"""
        exclude_ops = ['ts_backfill', 'right_tail', 'left_tail', 'tail', 'bucket', 'truncate', 'winsorize', 'clamp',
                       'ts_target_tvr_decay', 'ts_target_tvr_hump', 'densify']
        single_ops = [op for op in basic_ops if not op.startswith('vec_') and op not in exclude_ops]
        
        for field in self.fields:
            field_expr = self._get_field_expr(field)
            self.expressions.append(field_expr)
            self.expressions.append(f'-{field_expr}')
            
            for op in single_ops:
                self.expressions.append(f'{op}({field_expr})')
                self.expressions.append(f'-{op}({field_expr})')
    
    def _generate_ts_operators(self):
        """ç”Ÿæˆæ—¶é—´åºåˆ—æ“ä½œç¬¦è¡¨è¾¾å¼"""
        ts_ops_window = [
            'ts_rank', 'ts_mean', 'ts_sum', 'ts_std_dev', 
            'ts_delta', 'ts_delay', 'ts_max', 'ts_min',
            'ts_product', 'ts_zscore', 'ts_ir', 'ts_decay_linear',
            'ts_arg_max', 'ts_arg_min', 'ts_scale',
            'ts_median', 'ts_kurtosis', 'ts_skewness'
        ]
        
        ts_ops_lookback = ['ts_backfill', 'ts_av_diff', 'ts_returns']
        windows = [5, 10, 20, 60]
        
        for field in self.fields[::2]:
            field_expr = self._get_field_expr(field)
            for op in ts_ops_window:
                for window in windows[::2]:
                    self.expressions.append(f'{op}({field_expr}, {window})')
            
            for op in ts_ops_lookback:
                for window in windows[::2]:
                    self.expressions.append(f'{op}({field_expr}, {window})')
    
    def _generate_tail_operators(self):
        """ç”Ÿæˆtailç±»æ“ä½œç¬¦è¡¨è¾¾å¼"""
        for field in self.fields[::3]:
            field_expr = self._get_field_expr(field)
            for minimum in [0, 0.5, 1]:
                self.expressions.append(f'right_tail({field_expr}, minimum={minimum})')
            for maximum in [0, -0.5, -1]:
                self.expressions.append(f'left_tail({field_expr}, maximum={maximum})')
            self.expressions.append(f'tail({field_expr}, lower=-1, upper=1, newval=0)')
            self.expressions.append(f'tail({field_expr}, lower=-2, upper=2, newval=0)')
    
    def _generate_bucket_operators(self):
        """ç”Ÿæˆbucketæ“ä½œç¬¦è¡¨è¾¾å¼ - å¿…é¡»ä½¿ç”¨å‘½åå‚æ•°"""
        for field in self.fields[::4]:
            field_expr = self._get_field_expr(field)
            rank_expr = f'rank({field_expr})'
            self.expressions.append(f'bucket({rank_expr}, range="0, 1, 0.1")')
            self.expressions.append(f'bucket({rank_expr}, range="0, 1, 0.05")')
            self.expressions.append(f'bucket({rank_expr}, buckets="0.2,0.4,0.6,0.8")')
    
    def _generate_truncate_winsorize_operators(self):
        """ç”Ÿæˆtruncateå’Œwinsorizeæ“ä½œç¬¦è¡¨è¾¾å¼ - å¿…é¡»ä½¿ç”¨å‘½åå‚æ•°"""
        for field in self.fields[::3]:
            field_expr = self._get_field_expr(field)
            self.expressions.append(f'truncate({field_expr}, maxPercent=0.01)')
            self.expressions.append(f'truncate({field_expr}, maxPercent=0.05)')
            self.expressions.append(f'truncate(rank({field_expr}), maxPercent=0.02)')
            
            self.expressions.append(f'winsorize({field_expr}, std=3)')
            self.expressions.append(f'winsorize({field_expr}, std=4)')
            self.expressions.append(f'winsorize(rank({field_expr}), std=2.5)')
    
    def _generate_clamp_operators(self):
        """ç”Ÿæˆclampæ“ä½œç¬¦è¡¨è¾¾å¼ - å¿…é¡»ä½¿ç”¨å‘½åå‚æ•°"""
        for field in self.fields[::4]:
            field_expr = self._get_field_expr(field)
            self.expressions.append(f'clamp({field_expr}, lower=0.95, upper=1.05)')
            self.expressions.append(f'clamp({field_expr}, lower=-0.1, upper=0.1)')
            self.expressions.append(f'clamp(-ts_returns({field_expr}, 5), lower=-0.05, upper=0.05)')
            self.expressions.append(f'clamp(ts_delta({field_expr}, 10), lower=-0.1, upper=0.1)')
    
    def _generate_ts_target_tvr_operators(self):
        """ç”Ÿæˆts_target_tvrç³»åˆ—æ“ä½œç¬¦ - å¿…é¡»ä½¿ç”¨å®Œæ•´çš„å‘½åå‚æ•°"""
        for field in self.fields[::4]:
            field_expr = self._get_field_expr(field)
            self.expressions.append(f'ts_target_tvr_decay({field_expr}, lambda_min=0, lambda_max=1, target_tvr=0.1)')
            self.expressions.append(f'ts_target_tvr_decay({field_expr}, lambda_min=0, lambda_max=0.5, target_tvr=0.05)')
            self.expressions.append(f'ts_target_tvr_hump({field_expr}, lambda_min=0, lambda_max=1, target_tvr=0.1)')
            self.expressions.append(f'ts_target_tvr_hump({field_expr}, lambda_min=0, lambda_max=0.5, target_tvr=0.05)')
        
        if len(self.fields) >= 2:
            for i, field1 in enumerate(self.fields[:3]):
                for field2 in self.fields[i+1:min(i+2, len(self.fields))]:
                    expr1 = self._get_field_expr(field1)
                    expr2 = self._get_field_expr(field2)
                    self.expressions.append(f'ts_target_tvr_delta_limit({expr1}, {expr2}, lambda_min=0, lambda_max=1, target_tvr=0.1)')
    
    def _generate_densify_operators(self):
        """ç”Ÿæˆdensifyæ“ä½œç¬¦ - ç”¨äºä¼˜åŒ–åˆ†ç»„å­—æ®µçš„æ¡¶æ•°é‡"""
        groups = ['subindustry', 'industry', 'sector']
        
        for group in groups:
            self.expressions.append(f'densify({group})')
            
            for field in self.fields[:3]:
                field_expr = self._get_field_expr(field)
                self.expressions.append(f'group_rank({field_expr}, densify({group}))')
                self.expressions.append(f'group_neutralize({field_expr}, densify({group}))')

    def _generate_group_operators(self):
        """ç”Ÿæˆåˆ†ç»„æ“ä½œç¬¦è¡¨è¾¾å¼"""
        group_ops = [
            'group_rank', 'group_zscore', 'group_neutralize',
            'group_mean', 'group_scale', 'group_normalize'
        ]
        
        groups = ['subindustry', 'industry', 'sector']
        
        for field in self.fields[::3]:
            field_expr = self._get_field_expr(field)
            
            for op in group_ops:
                for group in groups[:2]:
                    if op == 'group_mean':
                        self.expressions.append(f'{op}({field_expr}, 1, {group})')
                    else:
                        self.expressions.append(f'{op}({field_expr}, {group})')
    
    def _generate_dual_field(self):
        """ç”ŸæˆåŒå­—æ®µæ“ä½œç¬¦è¡¨è¾¾å¼"""
        dual_ops = ['add', 'subtract', 'multiply', 'divide', 'power']
        
        for i, field1 in enumerate(self.fields[:5]):
            for field2 in self.fields[i+1:min(i+3, len(self.fields))]:
                expr1 = self._get_field_expr(field1)
                expr2 = self._get_field_expr(field2)
                
                for op in dual_ops[:3]:
                    self.expressions.append(f'{op}({expr1}, {expr2})')
    
    def _generate_triple_param(self):
        """ç”Ÿæˆä¸‰å‚æ•°æ“ä½œç¬¦è¡¨è¾¾å¼ï¼ˆç²¾é€‰ï¼‰"""
        triple_ops = ['ts_corr', 'ts_covariance', 'if_else']
        
        if len(self.fields) >= 2:
            field1 = self._get_field_expr(self.fields[0])
            field2 = self._get_field_expr(self.fields[1])
            
            for op in ['ts_corr', 'ts_covariance']:
                for window in [20, 60]:
                    self.expressions.append(f'{op}({field1}, {field2}, {window})')
        
        for field in self.fields[::4]:
            field_expr = self._get_field_expr(field)
            self.expressions.append(f'if_else(greater({field_expr}, 0), {field_expr}, -{field_expr})')

# ============================= æ ¸å¿ƒä¿®å¤ï¼šæ¨¡æ‹Ÿä»»åŠ¡å¤„ç†å‡½æ•° =============================
def generate_sim_data_fixed(alpha_item, region, uni, neut):
    """
    ä¿®å¤ç‰ˆï¼šç”Ÿæˆå•æ¡æ¨¡æ‹Ÿæ•°æ®ï¼ˆè§£å†³400é”™è¯¯ï¼‰
    alpha_item: å•ä¸ªä»»åŠ¡å…ƒç»„ (expr, decay)
    """
    alpha, decay = alpha_item
    simulation_data = {
        'type': 'REGULAR',
        'settings': {
            'instrumentType': 'EQUITY',
            'region': region,
            'universe': uni,
            'delay': 1,
            'decay': decay,
            'neutralization': neut,
            'truncation': 0.08,
            'pasteurization': 'ON',
            'testPeriod': 'P0Y',
            'unitHandling': 'VERIFY',
            'nanHandling': 'ON',
            'language': 'FASTEXPR',
            'visualization': False,
        },
        'regular': alpha
    }
    return simulation_data

def multi_simulate_fixed(alpha_pools, neut, region, universe, start):
    """
    ä¿®å¤ç‰ˆï¼šæ‰¹é‡æ¨¡æ‹Ÿå‡½æ•°
    1. è§£å†³400 Bad Requestï¼ˆå•ä»»åŠ¡ä¸åŒ…è£¹æ•°ç»„ï¼‰
    2. ä»»åŠ¡å¤±è´¥è‡ªåŠ¨è·³è¿‡ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
    3. å¢å¼ºå¼‚å¸¸å¤„ç†ï¼Œé¿å…å¡ä½
    """
    global s
    if s is None:
        s = login()
    
    brain_api_url = 'https://api.worldquantbrain.com'
    failed_tasks = []  # è®°å½•å¤±è´¥ä»»åŠ¡
    
    for x, pool in enumerate(alpha_pools):
        if x < start: 
            continue
        
        print(f"\n[Pool {x}] å¼€å§‹å¤„ç† {len(pool)} ä¸ªä»»åŠ¡...")
        progress_urls = []
        
        # éå†æ¯ä¸ªä»»åŠ¡ï¼Œé€ä¸ªå¤„ç†ï¼ˆå¤±è´¥è·³è¿‡ï¼‰
        for y, task in enumerate(pool):
            try:
                # ç”Ÿæˆå•æ¡æ¨¡æ‹Ÿæ•°æ®ï¼ˆä¸åŒ…è£¹æ•°ç»„ï¼‰
                sim_data = generate_sim_data_fixed(task, region, universe, neut)
                
                # æäº¤å‰æ·»åŠ å»¶è¿Ÿï¼Œé¿å…é™æµ
                time.sleep(GLOBAL_REQUEST_DELAY)
                
                # æ ¸å¿ƒä¿®å¤ï¼šå•ä»»åŠ¡ç›´æ¥æäº¤ï¼ˆéæ•°ç»„ï¼‰ï¼Œå¤šä»»åŠ¡æ‰ç”¨æ•°ç»„
                simulation_response = s.post(
                    'https://api.worldquantbrain.com/simulations',
                    json=sim_data  # å•ä»»åŠ¡ï¼šç›´æ¥ä¼ å­—å…¸ï¼ˆéæ•°ç»„ï¼‰
                )
                
                # å¤„ç†429é™æµ
                if simulation_response.status_code == 429:
                    retry_after = int(simulation_response.headers.get("Retry-After", 10))
                    print(f"âš  [Pool {x}-Task {y}] é™æµï¼Œç­‰å¾… {retry_after} ç§’...")
                    time.sleep(retry_after)
                    # é‡è¯•æäº¤
                    simulation_response = s.post(
                        'https://api.worldquantbrain.com/simulations',
                        json=sim_data
                    )
                
                simulation_response.raise_for_status()
                simulation_progress_url = simulation_response.headers.get('Location')
                
                if simulation_progress_url:
                    progress_urls.append((simulation_progress_url, task))
                    print(f"âœ… [Pool {x}-Task {y}] æäº¤æˆåŠŸ: {task[0][:50]}...")
                else:
                    print(f"âš  [Pool {x}-Task {y}] æ— è¿›åº¦URLï¼Œè·³è¿‡")
                    failed_tasks.append((x, y, task, "æ— è¿›åº¦URL"))
                    
            except requests.exceptions.HTTPError as e:
                error_msg = f"HTTPé”™è¯¯: {e.response.status_code} - {e.response.text[:100]}"
                print(f"âŒ [Pool {x}-Task {y}] æäº¤å¤±è´¥: {error_msg}")
                failed_tasks.append((x, y, task, error_msg))
                # è·³è¿‡å½“å‰ä»»åŠ¡ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                continue
            except Exception as e:
                error_msg = f"ç³»ç»Ÿé”™è¯¯: {str(e)[:100]}"
                print(f"âŒ [Pool {x}-Task {y}] æäº¤å¤±è´¥: {error_msg}")
                failed_tasks.append((x, y, task, error_msg))
                # é‡æ–°ç™»å½•ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if "401" in str(e) or "unauthorized" in str(e).lower():
                    print(f"ğŸ”„ é‡æ–°ç™»å½•...")
                    s = login()
                # è·³è¿‡å½“å‰ä»»åŠ¡ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                continue
        
        print(f"[Pool {x}] æäº¤å®Œæˆ - æˆåŠŸ: {len(progress_urls)} | å¤±è´¥: {len(failed_tasks)}")
        
        # æ£€æŸ¥ä»»åŠ¡è¿›åº¦ï¼ˆå¤±è´¥ä¸å½±å“åç»­ï¼‰
        for j, (progress, task) in enumerate(progress_urls):
            try:
                while True:
                    time.sleep(GLOBAL_REQUEST_DELAY)
                    simulation_progress = s.get(progress)
                    
                    if simulation_progress.headers.get("Retry-After"):
                        sleep_time = float(simulation_progress.headers["Retry-After"])
                        print(f"âš  [Pool {x}-Progress {j}] é™æµï¼Œç­‰å¾… {sleep_time} ç§’...")
                        time.sleep(sleep_time)
                        continue
                    
                    status = simulation_progress.json().get("status", "UNKNOWN")
                    if status in ["COMPLETE", "FAILED", "CANCELLED"]:
                        print(f"ğŸ“Š [Pool {x}-Progress {j}] çŠ¶æ€: {status}")
                        break
                    else:
                        print(f"âŒ› [Pool {x}-Progress {j}] çŠ¶æ€: {status}ï¼Œç­‰å¾…ä¸­...")
                        time.sleep(2)
                        
            except Exception as e:
                print(f"âŒ [Pool {x}-Progress {j}] è¿›åº¦æŸ¥è¯¢å¤±è´¥: {str(e)[:100]}")
                continue  # è·³è¿‡è¿›åº¦æŸ¥è¯¢å¤±è´¥çš„ä»»åŠ¡
        
        print(f"âœ… [Pool {x}] å¤„ç†å®Œæˆ")
    
    # è¾“å‡ºå¤±è´¥ä»»åŠ¡æ±‡æ€»
    if failed_tasks:
        print(f"\nğŸ“ å¤±è´¥ä»»åŠ¡æ±‡æ€»ï¼ˆå…±{len(failed_tasks)}ä¸ªï¼‰:")
        for idx, (x, y, task, err) in enumerate(failed_tasks[:5]):  # åªæ˜¾ç¤ºå‰5ä¸ª
            print(f"  - Pool{x}-Task{y}: {task[0][:50]}... | åŸå› : {err}")
        if len(failed_tasks) > 5:
            print(f"  - è¿˜æœ‰ {len(failed_tasks)-5} ä¸ªå¤±è´¥ä»»åŠ¡ï¼Œç•¥è¿‡æ˜¾ç¤º")
    else:
        print(f"\nğŸ‰ æ‰€æœ‰ä»»åŠ¡æäº¤æˆåŠŸï¼")

# ============================= ä¸»æµç¨‹ =============================
def main():
    """ä¸»æ‰§è¡Œå‡½æ•° - å®Œæ•´çš„æ‰§è¡Œæµç¨‹"""
    global s
    
    print("=" * 70)
    print(f"WorldQuant Brain æ‰¹é‡Alphaç”Ÿæˆ - å®Œæ•´æ“ä½œç¬¦ç‰ˆï¼ˆé˜²429+è‡ªåŠ¨è·³è¿‡å¤±è´¥ä»»åŠ¡ï¼‰")
    print("=" * 70)
    print(f"\né…ç½®: {DATASET_ID} | {REGION}/{UNIVERSE}/D{DELAY}")
    print(f"æ”¯æŒæ“ä½œç¬¦: {len(basic_ops + ts_ops)}ä¸ª")
    print(f"ä¸­æ€§åŒ–é…ç½®: {len(NEUTRALIZATIONS)}ä¸ª - {NEUTRALIZATIONS[:3]}...")
    print(f"âš  å•ä»»åŠ¡æäº¤æ¨¡å¼ï¼ˆä¿®å¤400é”™è¯¯ï¼‰| å¤±è´¥ä»»åŠ¡è‡ªåŠ¨è·³è¿‡")
    print("-" * 70)
    
    # 1. ç¡®ä¿ç™»å½•æˆåŠŸ
    print(f"\n[1/6] éªŒè¯ç™»å½•çŠ¶æ€...")
    if s is None:
        print(f"  â†’ æ­£åœ¨ç™»å½•...")
        s = login()
    
    if s is None:
        print(f"âŒ ç™»å½•å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        return
    
    print(f"  âœ“ ç™»å½•çŠ¶æ€æ­£å¸¸")
    
    # 2. è·å–æ•°æ®å­—æ®µ
    print(f"\n[2/6] è·å–æ•°æ®å­—æ®µ...")
    try:
        gdf = get_datafields(
            s=s,
            instrument_type='EQUITY',
            region=REGION,
            delay=DELAY,
            universe=UNIVERSE,
            dataset_id=DATASET_ID
        )
        
        if gdf.empty or len(gdf) == 0:
            print(f"âš  è­¦å‘Šï¼šæœªè·å–åˆ°ä»»ä½•å­—æ®µï¼ä½¿ç”¨é»˜è®¤æµ‹è¯•å­—æ®µç»§ç»­...")
            fields = ['close', 'volume', 'open', 'high', 'low']
        else:
            all_fields = gdf[gdf['type'] == DATA_TYPE]['id'].tolist()
            if len(all_fields) > FIELD_RANGE_SIZE:
                start_idx = random.randint(0, len(all_fields) - FIELD_RANGE_SIZE)
                fields = all_fields[start_idx : start_idx + FIELD_RANGE_SIZE]
            else:
                fields = all_fields
        
        print(f"  âœ“ æ€»å­—æ®µ: {len(all_fields) if 'all_fields' in locals() else len(fields)} | ä½¿ç”¨: {len(fields)}")
        if fields:
            print(f"  ç¤ºä¾‹: {fields[0]}")
            
    except Exception as e:
        print(f"âŒ è·å–æ•°æ®å­—æ®µå¤±è´¥: {str(e)[:100]}")
        print("â†’ ä½¿ç”¨é»˜è®¤æµ‹è¯•å­—æ®µç»§ç»­...")
        fields = ['close', 'volume', 'open', 'high', 'low']
        DATA_TYPE = 'MATRIX'
    
    # 3. ç”Ÿæˆè¡¨è¾¾å¼
    print(f"\n[3/6] ç”ŸæˆAlphaè¡¨è¾¾å¼...")
    try:
        generator = AlphaExpressionGenerator(fields, DATA_TYPE)
        expressions = generator.generate_all()
        
        print(f"  âœ“ è¡¨è¾¾å¼æ€»æ•°: {len(expressions)}")
        print(f"  é¢„è®¡æ‰¹æ¬¡: {int(len(expressions) / 65) if expressions else 0}")
        if expressions:
            print(f"  ç¤ºä¾‹: {expressions[0]}")
    except Exception as e:
        print(f"âŒ ç”Ÿæˆè¡¨è¾¾å¼å¤±è´¥: {str(e)[:100]}")
        expressions = [f"rank(ts_returns({field}, 5))" for field in fields[:3]]
        print(f"â†’ ä½¿ç”¨ç®€åŒ–è¡¨è¾¾å¼ç»§ç»­: {expressions}")
    
    # 4. ç”ŸæˆFirst Order
    print(f"\n[4/6] ç”ŸæˆFirst Order...")
    try:
        first_order = first_order_factory(expressions, ops_set)
        print(f"  âœ“ First Order: {len(first_order)}")
    except Exception as e:
        print(f"âŒ ç”ŸæˆFirst Orderå¤±è´¥: {str(e)[:100]}")
        first_order = expressions[:10]
        print(f"â†’ ä½¿ç”¨ç®€åŒ–First Orderç»§ç»­: {len(first_order)}ä¸ª")
    
    # 5. å‡†å¤‡ä»»åŠ¡
    print(f"\n[5/6] å‡†å¤‡ä»»åŠ¡...")
    try:
        tasks = [(expr, INIT_DECAY) for expr in first_order]
        random.shuffle(tasks)
        pools = load_task_pool(tasks, TASK_POOL_SIZE, CONCURRENT_SIMS)
        
        print(f"  âœ“ ä»»åŠ¡æ•°: {len(tasks)}")
        print(f"  ä»»åŠ¡æ± : {TASK_POOL_SIZE} | å¹¶å‘: {CONCURRENT_SIMS}")
        print(f"  è¡°å‡: {INIT_DECAY}")
        
        if pools:
            print(f"  ç¤ºä¾‹ä»»åŠ¡: {pools[0][0][0][:50]}...")
    except Exception as e:
        print(f"âŒ å‡†å¤‡ä»»åŠ¡å¤±è´¥: {str(e)[:100]}")
        print("â†’ ç¨‹åºæ— æ³•ç»§ç»­ï¼Œé€€å‡º")
        return
    
    # 6. æ‰¹é‡æ¨¡æ‹Ÿï¼ˆä½¿ç”¨ä¿®å¤ç‰ˆå‡½æ•°ï¼‰
    print(f"\n[6/6] æ‰¹é‡æ¨¡æ‹Ÿ...")
    total_neutralizations = len(NEUTRALIZATIONS)
    
    if total_neutralizations == 0:
        print(f"âš  æ²¡æœ‰ä¸­æ€§åŒ–é…ç½®ï¼Œç¨‹åºé€€å‡º")
        return
    
    # éå†æ‰€æœ‰ä¸­æ€§åŒ–é…ç½®ï¼Œå¤±è´¥ä¸ç»ˆæ­¢
    for idx, neutralization in enumerate(NEUTRALIZATIONS, 1):
        print("\n" + "=" * 70)
        print(f"æ‰§è¡Œä¸­æ€§åŒ–é…ç½® [{idx}/{total_neutralizations}]: {neutralization}")
        print("=" * 70)
        
        try:
            # è°ƒç”¨ä¿®å¤ç‰ˆæ¨¡æ‹Ÿå‡½æ•°
            multi_simulate_fixed(
                alpha_pools=pools,
                neut=neutralization,
                region=REGION,
                universe=UNIVERSE,
                start=0
            )
            print(f"  âœ“ ä¸­æ€§åŒ–é…ç½® {neutralization} æ‰§è¡Œå®Œæˆ")
        except Exception as e:
            error_msg = str(e)[:150]
            print(f"âŒ æ‰§è¡Œä¸­æ€§åŒ–é…ç½® {neutralization} å¤±è´¥: {error_msg}")
            print(f"â†’ è·³è¿‡å½“å‰é…ç½®ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª...")
            # å¢åŠ å»¶è¿Ÿï¼Œé¿å…è¿ç»­å¤±è´¥
            time.sleep(5)
            continue
    
    print("\n" + "=" * 70)
    print(f"âœ… æ‰€æœ‰é…ç½®æ‰§è¡Œå®Œæˆï¼")
    print("=" * 70)

# ============================= ç¨‹åºå…¥å£ =============================
if __name__ == "__main__":
    """ç¨‹åºæ‰§è¡Œå…¥å£ - å…³é”®ï¼šç¡®ä¿mainå‡½æ•°è¢«è°ƒç”¨"""
    # åˆå§‹åŒ–å…¨å±€é…ç½®ï¼ˆä»machine_libå¯¼å…¥ï¼‰
    GLOBAL_REQUEST_DELAY = 1.0
    MAX_RETRIES = 5
    RETRY_BACKOFF_FACTOR = 2
    
    # åŸºç¡€æ“ä½œç¬¦å®šä¹‰ï¼ˆé˜²æ­¢ç¼ºå¤±ï¼‰
    basic_ops = ["reverse", "inverse", "rank", "zscore", "quantile", "normalize",
                 "right_tail", "left_tail", "tail", "bucket", "truncate", "winsorize",
                 "clamp", "ts_target_tvr_decay", "ts_target_tvr_hump", "densify",
                 "group_rank", "group_zscore", "group_neutralize", "group_mean",
                 "group_scale", "group_normalize", "add", "subtract", "multiply",
                 "divide", "power", "ts_corr", "ts_covariance", "if_else", "greater"]
     
    ts_ops = ["ts_rank", "ts_zscore", "ts_delta",  "ts_sum", "ts_delay", 
              "ts_std_dev", "ts_mean",  "ts_arg_min", "ts_arg_max","ts_scale", 
              "ts_quantile", "ts_backfill", "ts_av_diff", "ts_returns", "ts_product",
              "ts_ir", "ts_decay_linear", "ts_max", "ts_min", "ts_median",
              "ts_kurtosis", "ts_skewness", "ts_target_tvr_delta_limit"]
     
    ops_set = basic_ops + ts_ops
    
    try:
        # å…ˆç™»å½•
        s = login()
        # æ‰§è¡Œä¸»å‡½æ•°
        main()
    except KeyboardInterrupt:
        print(f"\n\nâš  ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
    except Exception as e:
        print(f"\n\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)[:200]}")
        import traceback
        traceback.print_exc()
